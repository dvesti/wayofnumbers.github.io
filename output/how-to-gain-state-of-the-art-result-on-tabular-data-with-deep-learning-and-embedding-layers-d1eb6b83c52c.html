<!DOCTYPE html>
<html lang="en">
    <head>
        <meta charset="utf-8">
        <meta http-equiv="X-UA-Compatible" content="IE=edge">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <meta name="author" content="Michael Li" />

        <meta name="description" content="How to Gain State-Of-The-Art Result on Tabular Data with Deep Learning and EmbeddingÂ Layers
" />
        <meta property="og:type" content="article" />
        <meta name="twitter:card" content="summary">

<meta name="keywords" content="Machine Learning, Artificial Intelligence, Machine Learning, " />

<meta property="og:title" content="How to Gain State-Of-The-Art Result on Tabular Data with Deep Learning and EmbeddingÂ Layers  - A different approach to Kaggle Blue Book Bulldozers Competition "/>
<meta property="og:url" content="https://wayofnumbers.com/how-to-gain-state-of-the-art-result-on-tabular-data-with-deep-learning-and-embedding-layers-d1eb6b83c52c" />
<meta property="og:description" content="How to Gain State-Of-The-Art Result on Tabular Data with Deep Learning and EmbeddingÂ Layers" />
<meta property="og:site_name" content="Way of Numbers" />
<meta property="og:article:author" content="Michael Li" />
<meta property="og:article:published_time" content="2020-01-30T11:13:53-06:00" />
<meta name="twitter:title" content="How to Gain State-Of-The-Art Result on Tabular Data with Deep Learning and EmbeddingÂ Layers  - A different approach to Kaggle Blue Book Bulldozers Competition ">
<meta name="twitter:description" content="How to Gain State-Of-The-Art Result on Tabular Data with Deep Learning and EmbeddingÂ Layers">
<meta property="og:image" content="/theme/images/apple-touch-icon-152x152.png" />
<meta name="twitter:image" content="/theme/images/apple-touch-icon-152x152.png" >

        <title>How to Gain State-Of-The-Art Result on Tabular Data with Deep Learning and EmbeddingÂ Layers  - A different approach to Kaggle Blue Book Bulldozers Competition  Â· Way of Numbers
</title>
        <link href="//netdna.bootstrapcdn.com/twitter-bootstrap/2.3.2/css/bootstrap-combined.min.css" rel="stylesheet">
        <link rel="stylesheet" type="text/css" href="https://wayofnumbers.com/theme/css/elegant.prod.css" media="screen">
        <link rel="stylesheet" type="text/css" href="https://wayofnumbers.com/theme/css/custom.css" media="screen">

        <link rel="shortcut icon" href="https://wayofnumbers.com/theme/images/favicon.ico" type="image/x-icon" />
        <link rel="icon" href="https://wayofnumbers.com/theme/images/apple-touch-icon-152x152.png" type="image/png" />
        <link rel="apple-touch-icon" href="https://wayofnumbers.com/theme/images/apple-touch-icon.png"  type="image/png" />
        <link rel="apple-touch-icon" sizes="57x57" href="https://wayofnumbers.com/theme/images/apple-touch-icon-57x57.png" type="image/png" />
        <link rel="apple-touch-icon" sizes="72x72" href="https://wayofnumbers.com/theme/images/apple-touch-icon-72x72.png" type="image/png" />
        <link rel="apple-touch-icon" sizes="76x76" href="https://wayofnumbers.com/theme/images/apple-touch-icon-76x76.png" type="image/png" />
        <link rel="apple-touch-icon" sizes="114x114" href="https://wayofnumbers.com/theme/images/apple-touch-icon-114x114.png" type="image/png" />
        <link rel="apple-touch-icon" sizes="120x120" href="https://wayofnumbers.com/theme/images/apple-touch-icon-120x120.png" type="image/png" />
        <link rel="apple-touch-icon" sizes="144x144" href="https://wayofnumbers.com/theme/images/apple-touch-icon-144x144.png" type="image/png" />
        <link rel="apple-touch-icon" sizes="152x152" href="https://wayofnumbers.com/theme/images/apple-touch-icon-152x152.png" type="image/png" />
        <link rel="apple-touch-icon" sizes="152x152" href="https://wayofnumbers.com/theme/images/apple-touch-icon-180x180.png" type="image/png" />
        <link href="https://wayofnumbers.com/feeds/all.atom.xml" type="application/atom+xml" rel="alternate" title="Way of Numbers - Full Atom Feed" />
<script>
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
     (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
     m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
     })(window,document,'script','//www.google-analytics.com/analytics.js','ga');
    ga('create', 'UA-148798026-1', 'auto');
    ga('send', 'pageview');
</script>


    </head>
    <body>
        <div id="content">
            <div class="navbar navbar-static-top">
                <div class="navbar-inner">
                    <div class="container-fluid">
                        <a class="btn btn-navbar" data-toggle="collapse" data-target=".nav-collapse">
                            <span class="icon-bar"></span>
                            <span class="icon-bar"></span>
                            <span class="icon-bar"></span>
                        </a>
                        <a class="brand" href="https://wayofnumbers.com/"><span class=site-name>Way of Numbers</span></a>
                        <div class="nav-collapse collapse">
                            <ul class="nav pull-right top-menu">
                                <li >
                                    <a href=
                                       https://wayofnumbers.com
                                    >Home</a>
                                </li>
                                <li ><a href="https://wayofnumbers.com/about-me">About&nbsp;Me</a></li>
                                <li ><a href="https://wayofnumbers.com/categories">Categories</a></li>
                                <li ><a href="https://wayofnumbers.com/tags">Tags</a></li>
                                <li ><a href="https://wayofnumbers.com/archives">Archives</a></li>
                                <li><form class="navbar-search" action="https://wayofnumbers.com/search" onsubmit="return validateForm(this.elements['q'].value);"> <input type="text" class="search-query" placeholder="Search" name="q" id="tipue_search_input"></form></li>
                            </ul>
                        </div>
                    </div>
                </div>
            </div>
            <div class="container-fluid">
                <div class="row-fluid">
                    <div class="span1"></div>
                    <div class="span10">
<article itemscope>
<div class="row-fluid">
    <header class="page-header span10 offset2">
        <h1>
            <a href="https://wayofnumbers.com/how-to-gain-state-of-the-art-result-on-tabular-data-with-deep-learning-and-embedding-layers-d1eb6b83c52c">
                How to Gain State-Of-The-Art Result on Tabular Data with Deep Learning and Embedding&nbsp;Layers
                <small class="subtitle">
                    A different approach to Kaggle Blue Book Bulldozers Competition
                </small>
            </a>
        </h1>
    </header>
</div>

<div class="row-fluid">
    <div class="span2 table-of-content">
        <nav>
        <h4>Contents</h4>
        <div class="toc">
<ul>
<li><a href="#motivation">Motivation</a></li>
<li><a href="#loading-data">LoadingÂ Data</a></li>
<li><a href="#sorting-the-training-set">Sorting the TrainingÂ Set</a></li>
<li><a href="#data-pre-processing">DataÂ Pre-Processing</a></li>
<li><a href="#building-the-model">Building theÂ Model</a></li>
<li><a href="#building-the-model_1">Building theÂ Model</a></li>
<li><a href="#a-couple-of-more-words-on-embedding-layers">A Couple of More Words on EmbeddingÂ Layers</a></li>
</ul>
</div>
        </nav>
    </div>
    <div class="span8 article-content">
            
            
<p><img alt="Embeddings can be use other than word representations" src="https://cdn-images-1.medium.com/max/3010/0*iYOn4JtwX9d4pj-U.png"/><em>Embeddings can be use other than wordÂ representations</em></p>
<h2 id="motivation">Motivation<a class="headerlink" href="#motivation" title="Permanent link"> </a></h2>
<p>Tree-based models like Random Forest and XGBoost have become very popular in solving tabular(structured) data problems and gained a lot of tractions in Kaggle competitions lately. It has its very deserving reasons. However, in this article, I want to introduce a different approach from fast.aiâ€™s <strong>Tabular</strong> moduleÂ leveraging:</p>
<blockquote>
<p><strong>Deep Learning and EmbeddingÂ Layers.</strong></p>
</blockquote>
<p>This is a bit against industry consensus that Deep Learning is more for unstructured data like image, audio or <span class="caps">NLP</span>, and usually not suitable for handling tabular data. Yet, the introduction of embedding layers for the categorical data changed this perspective and weâ€™ll try to use<a href="http://fast.ai"> fast.ai</a>â€™s tabular module on the <a href="https://www.kaggle.com/c/bluebook-for-bulldozers/overview">Blue Book Bulldozers Competition</a> on <a href="http://kaggle.com">Kaggle</a> and see how far this approach canÂ go.</p>
<p><em>You can find the Kaggle Notebook ðŸ“”: <a href="https://www.kaggle.com/lymenlee/blue-book-bulldozer-fast-ai-deep-learning">here</a>.</em></p>
<h2 id="loading-data">Loading Data<a class="headerlink" href="#loading-data" title="Permanent link"> </a></h2>
<p><img alt="" src="https://cdn-images-1.medium.com/max/2880/1*xxZSbdIS_g_6A5vydjOBdg.png"/></p>
<p>First, letâ€™s import the necessary modules. The core one here is <strong>fastai.tabular</strong>:</p>
<div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">fastai</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">fastai.tabular</span> <span class="kn">import</span> <span class="o">*</span>
</pre></div>
<p>Then weâ€™ll read the data into a Pandas DataFrame. You can find the specific code in the Kaggle Notebook link on top of this article but for here, Iâ€™ll only show necessary code snippets to keep things as concise as possible. We will read in the <span class="caps">CSV</span> file into train_df and this will be the DataFrame weâ€™ll be mainly working on. We will also read in test_df which is the testÂ set.</p>
<p>Letâ€™s take a brief look at the data weâ€™re dealingÂ with:</p>
<div class="highlight"><pre><span></span>len(train_df), len(test_df)
(401125, 12457)
</pre></div>
<p><img alt="" src="https://cdn-images-1.medium.com/max/3006/1*-NlhS8DO3zNgsGA5TG3x8A.png"/></p>
<h2 id="sorting-the-training-set">Sorting the Training Set<a class="headerlink" href="#sorting-the-training-set" title="Permanent link"> </a></h2>
<p>This is to create a good validation set. It cannot be emphasized enough how important a good validation set is in making a successful model. Since we are predicting sales price data in the future, we need to make a validation set that all of its data is collected in the â€˜futureâ€™ of the training set. So we need to sort the training set first, then split the â€˜futureâ€™ part as the validationÂ set.</p>
<div class="highlight"><pre><span></span>train_df = train_df.sort_values(by='saledate', ascending=False)
train_df = train_df.reset_index(drop=True)
</pre></div>
<h2 id="data-pre-processing">Data Pre-Processing<a class="headerlink" href="#data-pre-processing" title="Permanent link"> </a></h2>
<p>The competitionâ€™s evaluation methods use <span class="caps">RMSLE</span> (root mean squared log error). So if we take the log of our prediction, we can just use the good old <span class="caps">RMSE</span> as our loss function. Itâ€™s just easier thisÂ way.</p>
<div class="highlight"><pre><span></span>train_df.SalePrice = np.log(train_df.SalePrice)
</pre></div>
<p>For <strong>Feature Engineering</strong>, since we will be using deep learning to tackle the problem and it is very good at feature extraction, weâ€™ll only do it on the saledate. This is the advantage of using a Deep Learning approach, it requires way less feature engineering and less dependent on domain knowledge. Weâ€™ll use the fast.aiâ€™s add_datepart function to for adding some more features related to the saleÂ date.</p>
<div class="highlight"><pre><span></span># The only feature engineering we do is add some meta-data from the sale date column, using 'add_datepart' function in fast.ai
add_datepart(train_df, "saledate", drop=False)
add_datepart(test_df, "saledate", drop=False)
</pre></div>
<p>What add_datepart does is it takes the saledate column and added a bunch of other columns like day of week, day of month, whether it is the start or end of a month, quarter and year, etc. These added features will offer more insights into the date and are relevant to user purchasing behaviors. For example, at the end of the year, the company will usually run promotions and prices will usuallyÂ decrease.</p>
<p>Letâ€™s check whether all these date related features got added into ourÂ DataFrame:</p>
<div class="highlight"><pre><span></span># check and see whether all date related meta data is added.
def display_all(df):
    with pd.option_context("display.max_rows", 1000, "display.max_columns", 1000): 
        display(df)

display_all(train_df.tail(10).T)
</pre></div>
<p><img alt="" src="https://cdn-images-1.medium.com/max/2862/1*oUayXXrPx9t-Wdtb4VmPYw.png"/></p>
<p>They did get added. Good. Now we need to do some data pre-processing since this DataFrame has quite some missing data and we also want to categorify and normalize the columns. With the fast.ai library, this is rather simple. We just specify the pre-processing methods we want into a Python list, likeÂ so:</p>
<div class="highlight"><pre><span></span># Defining pre-processing we want for our fast.ai DataBunch
procs=[FillMissing, Categorify, Normalize]
</pre></div>
<p>This variable procs will later be used to create the fast.ai DataBunch forÂ training.</p>
<h2 id="building-the-model">Building the Model<a class="headerlink" href="#building-the-model" title="Permanent link"> </a></h2>
<p>Letâ€™s look at the data types of each column to decide which ones are categorical and which ones areÂ continuous:</p>
<div class="highlight"><pre><span></span>train_df.dtypes
g = train_df.columns.to_series().groupby(train_df.dtypes).groups
g
</pre></div>
<p>Here are theÂ results:</p>
<p><img alt="" src="https://cdn-images-1.medium.com/max/2000/1*5tpHQuP9t2XjvX3z9mgPXA.png"/></p>
<p>Then weâ€™ll put all categorical columns into a list cat_vars and all continuous columns into a list cont_vars. These two variables will also be used to construct fast.aiÂ DataBunch.</p>
<div class="highlight"><pre><span></span># prepare categorical and continous data columns for building Tabular DataBunch.
cat_vars = ['SalesID', 'YearMade', 'MachineID', 'ModelID', 'datasource', 'auctioneerID', 'UsageBand', 'fiModelDesc', 'fiBaseModel', 'fiSecondaryDesc', 'fiModelSeries', 'fiModelDescriptor', 'ProductSize', 
            'fiProductClassDesc', 'state', 'ProductGroup', 'ProductGroupDesc', 'Drive_System', 'Enclosure', 'Forks', 'Pad_Type', 'Ride_Control', 'Stick', 'Transmission', 'Turbocharged', 'Blade_Extension', 
            'Blade_Width', 'Enclosure_Type', 'Engine_Horsepower', 'Hydraulics', 'Pushblock', 'Ripper', 'Scarifier', 'Tip_Control', 'Tire_Size', 'Coupler', 'Coupler_System', 'Grouser_Tracks', 'Hydraulics_Flow', 
            'Track_Type', 'Undercarriage_Pad_Width', 'Stick_Length', 'Thumb', 'Pattern_Changer', 'Grouser_Type', 'Backhoe_Mounting', 'Blade_Type', 'Travel_Controls', 'Differential_Type', 'Steering_Controls', 
            'saleYear', 'saleMonth', 'saleWeek', 'saleDay', 'saleDayofweek', 'saleDayofyear', 'saleIs_month_end', 'saleIs_month_start', 'saleIs_quarter_end', 'saleIs_quarter_start', 'saleIs_year_end', 
            'saleIs_year_start'
           ]

cont_vars = ['MachineHoursCurrentMeter', 'saleElapsed']
</pre></div>
<p>Weâ€™ll create another DataFrame df to feed into the DataBunch. We also specify the dependent variable as dep_varÂ .</p>
<div class="highlight"><pre><span></span># rearrange training set before feed into the databunch
dep_var = 'SalePrice'
df = train_df[cat_vars + cont_vars + [dep_var,'saledate']].copy()
</pre></div>
<p>Now is the time to create our validation set. We do this by cutting out a block of the most recent entries from the training set. How big the block should be? Well, the same size as the test set. Letâ€™s see theÂ code:</p>
<div class="highlight"><pre><span></span># Look at the time period of test set, make sure it's more recent
test_df['saledate'].min(), test_df['saledate'].max()

# Calculate where we should cut the validation set. We pick the most recent 'n' records in training set where n is the number of entries in test set. 
cut = train_df['saledate'][(train_df['saledate'] == train_df['saledate'][len(test_df)])].index.max()
cut

12621

# specify the valid_idx variable as the cut out range.
valid_idx = range(cut)
</pre></div>
<p>We first look at the time period of the test set and make sure it is more recent than all our training set. Then we calculate how many records we need to cutÂ out.</p>
<p>Finally, letâ€™s construct our DataBunch for training using fast.aiâ€™s datablock <span class="caps">API</span>:</p>
<div class="highlight"><pre><span></span># Use fast.ai datablock api to put our training data into the DataBunch, getting ready for training
data = (TabularList.from_df(df, path=path, cat_names=cat_vars, cont_names=cont_vars, procs=procs)
                   .split_by_idx(valid_idx)
                   .label_from_df(cols=dep_var, label_cls=FloatList)
                   .databunch())
</pre></div>
<h2 id="building-the-model_1">Building the Model<a class="headerlink" href="#building-the-model_1" title="Permanent link"> </a></h2>
<p>We will fire up a fast.ai tabular.learner from the DataBunch we just created. We want to limit the price range for our prediction to be within the history sale price range, so we need to calculate the y_range. Note that we multiplied the maximum of SalePrice by 1.2 so when we apply sigmoid, the upper limit will also be covered. This is a small trick to squeeze a bit more performance out of theÂ model.</p>
<div class="highlight"><pre><span></span>max_y = np.max(train_df['SalePrice'])*1.2
y_range = torch.tensor([0, max_y], device=defaults.device)
y_range

tensor([ 0.0000, 14.2363], device='cuda:0')
</pre></div>
<p>Now we can create ourÂ learner:</p>
<div class="highlight"><pre><span></span># Create our tabular learner. The dense layer is 1000 and 500 two layer NN. We used dropout, hai 
learn = tabular_learner(data, layers=[1000,500], ps=[0.001,0.01], emb_drop=0.04, y_range=y_range, metrics=rmse)
</pre></div>
<p>The single most important thing about fast.ai tabular_learner is the use of embedding layers for categorical data. This is the â€˜<strong>secret sauce</strong>â€™ that enables Deep Learning to be competitive in handling tabular data. With one embedding layer for each categorical variable, we introduced good interaction for the categorical variables and leverage Deep Learningâ€™s biggest strength: Automatic Feature Extraction. We also used Drop Out for both the dense layers and embedding layers for better regularization. The metrics of the learner is <span class="caps">RMSE</span> since weâ€™ve already taken the log of SalePrice. Letâ€™s look at theÂ model.</p>
<div class="highlight"><pre><span></span>TabularModel(
  (embeds): ModuleList(
    (0): Embedding(388505, 600)
    (1): Embedding(72, 18)
    (2): Embedding(331868, 600)
    (3): Embedding(5155, 192)
   ...
    (60): Embedding(3, 3)
    (61): Embedding(2, 2)
    (62): Embedding(3, 3)
  )
  (emb_drop): Dropout(p=0.04, inplace=False)
  (bn_cont): BatchNorm1d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (layers): Sequential(
    (0): Linear(in_features=2102, out_features=1000, bias=True)
    (1): ReLU(inplace=True)
    (2): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): Dropout(p=0.001, inplace=False)
    (4): Linear(in_features=1000, out_features=500, bias=True)
    (5): ReLU(inplace=True)
    (6): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (7): Dropout(p=0.01, inplace=False)
    (8): Linear(in_features=500, out_features=1, bias=True)
  )
)
</pre></div>
<p>As can be seen from the above, we have embedding layers for categorical columns, then followed by a drop out layer. We have a batch norm layer for the continuous columns, then we concatenate all of them (categorical embeddings + continuous variables) together and throw them into two fully connected layers with 1000 and 500 nodes, with Relu, BatchNorm, and Dropout in between. Quite standardÂ stuff.</p>
<p>Now that we have the model, letâ€™s use fast.aiâ€™s learning rate finder to find a good learningÂ rate:</p>
<div class="highlight"><pre><span></span>learn.lr_find()
learn.recorder.plot()
</pre></div>
<p><img alt="" src="https://cdn-images-1.medium.com/max/2000/1*V3leQPn16_RoGHmS-GJp3A.png"/></p>
<p>Weâ€™ll pick the learning rate at the end of the biggest learning rate curve slope:Â le-02</p>
<p>Letâ€™s do some training using fast.aiâ€™s One-Cycle Training approach. Note that we added some weight decay (0.2) forÂ regularization.</p>
<div class="highlight"><pre><span></span>learn.fit_one_cycle(2, 1e-2, wd=0.2)
</pre></div>
<p><img alt="" src="https://cdn-images-1.medium.com/max/2000/1*iTSVogV--iXyWqMtz7Gf6Q.png"/></p>
<p>We can train some more cycles with smaller learningÂ rate:</p>
<div class="highlight"><pre><span></span>learn.fit_one_cycle(5, 3e-4, wd=0.2)
</pre></div>
<p><img alt="" src="https://cdn-images-1.medium.com/max/2000/1*TpG8gJ4UoD_n74QyzJML3w.png"/></p>
<p>Weâ€™ve reached a score of <strong>0.223</strong> on our validation set. Since the competition is not accepting submissions, we can only look at the leaderboard to get a rough idea of how well this modelÂ performs:</p>
<p><img alt="" src="https://cdn-images-1.medium.com/max/2854/1*IuacQ30L1265EdtwImuMtw.png"/></p>
<p>The top place is <strong>0.229</strong>. Compare to this modelâ€™s <strong>0.223</strong>. We donâ€™t know how well it works on the test set but overall I think the result we got isnâ€™t bad atÂ all.</p>
<h2 id="a-couple-of-more-words-on-embedding-layers">A Couple of More Words on Embedding Layers<a class="headerlink" href="#a-couple-of-more-words-on-embedding-layers" title="Permanent link"> </a></h2>
<p>What makes everything click here is the embedding layers. Embedding is just a fancy word of saying mapping something to a vector. Like the word embedding that is getting more popular in <span class="caps">NLP</span>, it means using a vector (the size is arbitrary though, depending on tasks) to represent words, and those vectors are weights and can be trained viaÂ back-prop.</p>
<p><img alt="" src="https://cdn-images-1.medium.com/max/3104/0*9dWEOVdmzHOgrFj5"/></p>
<p>Similarly, for our case, we used embeddings on our categorical variables. Each column gets an embedding matrix that can be trained. And each unique column value gets a specific vector mapped to it. The beautiful thing about this is: <strong>with embedding, we can now develop â€˜semanticsâ€™ to the variable</strong>, â€˜semanticsâ€™ in the form of weights that matters to our sale price and can be extracted and trained via our deep neural network. The model will have the â€˜<strong>depth</strong>â€™ it needs to fit a big data setÂ well.</p>
<p>But donâ€™t take my words for it, or just look at the results of my humble little project. In a more glory case, there was <a href="https://arxiv.org/abs/1604.06737">this paper</a> by the folks who came 3rd in a Kaggle competition for something called <a href="https://www.kaggle.com/c/rossmann-store-sales/overview">Rossman</a> (prediction future sales). Among the top teams in the leaderboard, everyone else used some kind of heavy feature engineering, but by using embedding layers, they managed to score 3rd place with way less featureÂ engineering.</p>
<p>Whatâ€™s more interesting is, with embedding layers, you can actually visualize the variable projection in the embedding matrix space. Take the Rossman project as an example. They took a two-dimensional projection of the embedding matrix for the GermanÂ states.</p>
<blockquote>
<p>And if you circle some states on the embedding space and same states on the actual map. Youâ€™ll find out that they are scarily similar. The embedding layer actually discoveredÂ geography.</p>
</blockquote>


             
 
            
                <hr />
    <div class="author_blurb">
        <a href="https://medium.com/@lymenlee" target="_blank" rel="nofollow noopener noreferrer">
            <img src=/images/avatars/michael.png alt="Michael Li Avatar" title="Michael Li">
            <span class="author_name">Michael Li</span>
        </a>
        is the creator and lead developer of this site.
    </div>

            






            <hr/>
            <aside>
            <nav>
            <ul class="articles-timeline">
                <li class="previous-article">Â« <a href="https://wayofnumbers.com/no-human-can-beat-alphago-so-what-3401b40fa0f0" title="Previous: No Human Can Beat AlphaGo, and Itâ€™s a GoodÂ Thing - Why Go master Lee Se-Dol should not feel sorry for losing to AlphaGo">No Human Can Beat AlphaGo, and Itâ€™s a GoodÂ Thing <small class="subtitle">Why Go master Lee Se-Dol should not feel sorry for losing to AlphaGo</small></a></li>
                <li class="next-article"><a href="https://wayofnumbers.com/another-self-driving-car-accident-another-ai-development-lesson-b2ce3dbb4444" title="Next: Another Self-Driving Car Accident, Another AI DevelopmentÂ Lesson - What could be learned from Uberâ€™s Self-Driving Car accident as a Data Scientist">Another Self-Driving Car Accident, Another AI DevelopmentÂ Lesson <small class="subtitle">What could be learned from Uberâ€™s Self-Driving Car accident as a Data Scientist</small></a> Â»</li>
            </ul>
            </nav>
            </aside>
        </div>
        <section id="article-sidebar" class="span2">
            <h4>Published</h4>
            <time itemprop="dateCreated" datetime="2020-01-30T11:13:53-06:00">Jan 30, 2020</time>
            <h4>Category</h4>
            <a class="category-link" href="https://wayofnumbers.com/categories#machine-learning-ref">Machine Learning</a>
            <h4>Tags</h4>
            <ul class="list-of-tags tags-in-article">
                <li><a href="https://wayofnumbers.com/tags#artificial-intelligence-ref">Artificial Intelligence
                    <span>7</span>
</a></li>
                <li><a href="https://wayofnumbers.com/tags#machine-learning-ref">Machine Learning
                    <span>20</span>
</a></li>
            </ul>
<h4>Stay in Touch</h4>
<div id="sidebar-social-link">
    <a href="https://twitter.com/lymenlee" title="My Twitter" target="_blank" rel="nofollow noopener noreferrer">
        <svg xmlns="http://www.w3.org/2000/svg" aria-label="Twitter" role="img" viewBox="0 0 512 512"><rect width="512" height="512" rx="15%" fill="#1da1f3"/><path fill="#fff" d="M437 152a72 72 0 0 1-40 12 72 72 0 0 0 32-40 72 72 0 0 1-45 17 72 72 0 0 0-122 65 200 200 0 0 1-145-74 72 72 0 0 0 22 94 72 72 0 0 1-32-7 72 72 0 0 0 56 69 72 72 0 0 1-32 1 72 72 0 0 0 67 50 200 200 0 0 1-105 29 200 200 0 0 0 309-179 200 200 0 0 0 35-37"/></svg>
    </a>
    <a href="https://github.com/wayofnumbers" title="GitHub" target="_blank" rel="nofollow noopener noreferrer">
        <svg xmlns="http://www.w3.org/2000/svg" aria-label="GitHub" role="img" viewBox="0 0 512 512"><rect width="512" height="512" rx="15%" fill="#1B1817"/><path fill="#fff" d="M335 499c14 0 12 17 12 17H165s-2-17 12-17c13 0 16-6 16-12l-1-50c-71 16-86-28-86-28-12-30-28-37-28-37-24-16 1-16 1-16 26 2 40 26 40 26 22 39 59 28 74 22 2-17 9-28 16-35-57-6-116-28-116-126 0-28 10-51 26-69-3-6-11-32 3-67 0 0 21-7 70 26 42-12 86-12 128 0 49-33 70-26 70-26 14 35 6 61 3 67 16 18 26 41 26 69 0 98-60 120-117 126 10 8 18 24 18 48l-1 70c0 6 3 12 16 12z"/></svg>
    </a>
    <a href="www.linkedin.com/in/michael-li-dfw" title="LinkedIn" target="_blank" rel="nofollow noopener noreferrer">
        <svg xmlns="http://www.w3.org/2000/svg" aria-label="LinkedIn" role="img" viewBox="0 0 512 512" fill="#fff"><rect width="512" height="512" rx="15%" fill="#0077b5"/><circle cx="142" cy="138" r="37"/><path stroke="#fff" stroke-width="66" d="M244 194v198M142 194v198"/><path d="M276 282c0-20 13-40 36-40 24 0 33 18 33 45v105h66V279c0-61-32-89-76-89-34 0-51 19-59 32"/></svg>
    </a>
</div>
            



<!-- Begin MailChimp Signup Form -->
<div id="mc-embed-signup">
<form action="https://github.us17.list-manage.com/subscribe/post?u=c212184cc0965bdf1658f69f0&amp;id=5677a7b75e" method="post" id="mc-embedded-subscribe-form" name="mc-embedded-subscribe-form" class="validate" target="_blank" novalidate>
<h4>Get Monthly Updates</h4>
<input type="email" value="" name="EMAIL" class="email" id="mce-EMAIL" placeholder="Enter your email..." required>
<div class="clear"><input type="submit" value="Send me Free Updates" name="subscribe" id="mc-embedded-subscribe" class="button"></div>
</form>
</div>
<!--End mc_embed_signup-->




            



        </section>
</div>
</article>
                    </div>
                    <div class="span1"></div>
                </div>
            </div>
        </div>
<footer>
    <div>
        Content licensed under <a rel="license nofollow noopener noreferrer"
    href="http://creativecommons.org/licenses/by/4.0/" target="_blank">
    Creative Commons Attribution 4.0 International License</a>.
    </div>

    <div>
        <span class="site-name">Way of Numbers</span> - Data science for the rest of us.
    </div>



    <div id="fpowered">
        Powered by: <a href="http://getpelican.com/" title="Pelican Home Page" target="_blank" rel="nofollow noopener noreferrer">Pelican</a>
        Theme: <a href="https://elegant.oncrashreboot.com/" title="Theme Elegant Home Page" target="_blank" rel="nofollow noopener noreferrer">Elegant</a>
        Hosted on:
        <a href=https://www.netlify.com/ target="_blank" rel="nofollow noopener noreferrer">
            Netlify
        </a>
    </div>
</footer>            <script src="//code.jquery.com/jquery.min.js"></script>
        <script src="//netdna.bootstrapcdn.com/twitter-bootstrap/2.3.2/js/bootstrap.min.js"></script>
        <script>
            function validateForm(query)
            {
                return (query.length > 0);
            }
        </script>

    <script>
    (function () {
        if (window.location.hash.match(/^#comment-\d+$/)) {
            $('#comment_thread').collapse('show');
        }
    })();
    window.onhashchange=function(){
        if (window.location.hash.match(/^#comment-\d+$/))
            window.location.reload(true);
    }
    $('#comment_thread').on('shown', function () {
        var link = document.getElementById('comment-accordion-toggle');
        var old_innerHTML = link.innerHTML;
        $(link).fadeOut(200, function() {
            $(this).text('Click here to hide comments').fadeIn(200);
        });
        $('#comment_thread').on('hidden', function () {
            $(link).fadeOut(200, function() {
                $(this).text(old_innerHTML).fadeIn(200);
            });
        })
    })
</script>

    </body>
    <!-- Theme: Elegant built for Pelican
        License : MIT -->
</html>