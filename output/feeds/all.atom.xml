<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>Way of Numbers</title><link href="https://wayofnumbers.github.io/" rel="alternate"></link><link href="https://wayofnumbers.github.io/feeds/all.atom.xml" rel="self"></link><id>https://wayofnumbers.github.io/</id><updated>2019-09-16T20:00:00-05:00</updated><subtitle>Data science for the rest of us.</subtitle><entry><title>How I Trained Computer to Learn Calligraphy Styles: Part 2</title><link href="https://wayofnumbers.github.io/chinese-calligraphy-classifier-2.html" rel="alternate"></link><published>2019-09-16T20:00:00-05:00</published><updated>2019-09-16T20:00:00-05:00</updated><author><name>Michael Li</name></author><id>tag:wayofnumbers.github.io,2019-09-16:/chinese-calligraphy-classifier-2.html</id><summary type="html">&lt;p&gt;Fine-tune model for Chinese Calligraphy Classifier with fast.ai&amp;nbsp;library&lt;/p&gt;</summary><content type="html">&lt;p&gt;Build a Deep Learning Model with fast.ai&amp;nbsp;Library&lt;/p&gt;
&lt;p&gt;&lt;img alt="Photo by Kon Karampelas on Unsplash" src="https://cdn-images-1.medium.com/max/12000/0*gzpUfcpouuU10xO1"&gt;&lt;em&gt;Photo by &lt;a href="https://unsplash.com/@konkarampelas?utm_source=medium&amp;amp;utm_medium=referral"&gt;Kon Karampelas&lt;/a&gt; on &lt;a href="https://unsplash.com?utm_source=medium&amp;amp;utm_medium=referral"&gt;Unsplash&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;I wanted to start a series of posts for the projects I finished/polished for my &lt;a href="https://course.fast.ai/"&gt;Practical Deep Learning for Coders&lt;/a&gt; fast.ai course. Since I’m pretty green on &lt;span class="caps"&gt;ML&lt;/span&gt;/&lt;span class="caps"&gt;DL&lt;/span&gt; field, I hope the challenges I faced and overcome could be of value for other people experiencing the same&amp;nbsp;journey.&lt;/p&gt;
&lt;p&gt;Model &lt;a href="https://medium.com/@lymenlee/deep-learning-models-by-fast-ai-library-c1cccc13e2b3"&gt;1&lt;/a&gt; ・&lt;a href="https://medium.com/datadriveninvestor/chinese-calligraphy-classifier-fine-tuning-cbfbf0e304d8"&gt;1a&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;Making It Even&amp;nbsp;Better&lt;/h3&gt;
&lt;p&gt;In my &lt;a href="https://medium.com/datadriveninvestor/deep-learning-models-by-fast-ai-library-c1cccc13e2b3"&gt;last post&lt;/a&gt;, I explained the approach I take for this image recognition problem using fast.ai library. As you can see, once we get the data down to a fast.ai ImageDataBunch, the code is rather simple and we achieve a 90% accuracy rate, which is quite impressive considering the quality of our data(randomly downloaded from Google/Baidu search without much data cleaning). Now, can we do better?
&lt;a href="https://www.datadriveninvestor.com/2019/03/03/editors-pick-5-machine-learning-books/"&gt;&lt;strong&gt;&lt;span class="caps"&gt;DDI&lt;/span&gt; Editor&amp;#8217;s Pick: 5 Machine Learning Books That Turn You from Novice to Expert | Data Driven…&lt;/strong&gt;
&lt;em&gt;The booming growth in the Machine Learning industry has brought renewed interest in people about Artificial…&lt;/em&gt;www.datadriveninvestor.com&lt;/a&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;h1&gt;Turns out, we&amp;nbsp;can!&lt;/h1&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;img alt="" src="https://cdn-images-1.medium.com/max/2000/1*sz46EDt2HU_N2YecCXJ9ng.jpeg"&gt;&lt;/p&gt;
&lt;p&gt;How? Well, there are two things in our prior pipeline that could&amp;nbsp;improve:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Image Pre-processing&amp;nbsp;Tweak&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Model Training Fine&amp;nbsp;Tune.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Let’s dive&amp;nbsp;deeper.&lt;/p&gt;
&lt;h3&gt;Image Pre-Processing&amp;nbsp;Tweak&lt;/h3&gt;
&lt;p&gt;Remember when we import our data into fast.ai ImageDataBunch, we used the following&amp;nbsp;code:&lt;/p&gt;
&lt;p&gt;&lt;img alt="" src="https://cdn-images-1.medium.com/max/2000/0*Prt5fbhL-qj1OoQE.png"&gt;&lt;/p&gt;
&lt;p&gt;Notice that on our image pre-processing, i.e. get_transforms function, we didn’t give it any parameter and just used the default. The default will try to apply a variety of image augmentation techniques to make the image data-set generalize better, like flipping, warping, rotating, cropping, etc. This is good, fast.ai library helped us do the ‘best practice’ for the majority of the cases. But in our case here, some default might not work that&amp;nbsp;well.&lt;/p&gt;
&lt;p&gt;The biggest one is ‘flipping’. Because we are trying to classify calligraphy artworks and in real life, it will never randomly flip left/right or up/down. So making the images flips randomly will not reflect the real-life cases and thus won’t help with our training&amp;nbsp;accuracy.&lt;/p&gt;
&lt;p&gt;To fix this, we tweaked our code as&amp;nbsp;below:&lt;/p&gt;
&lt;p&gt;&lt;img alt="" src="https://cdn-images-1.medium.com/max/2000/1*9Gv0vDlF12MPKznehyU1LA.png"&gt;&lt;/p&gt;
&lt;p&gt;Notice we pass do_flip=False into the get_transforms function, thus telling the module to not randomly flipping our images during&amp;nbsp;importing.&lt;/p&gt;
&lt;h3&gt;Model Training Fine&amp;nbsp;Tune&lt;/h3&gt;
&lt;p&gt;Now that the image pre-processing is done. We can re-structure out model training to avoid overfitting and achieve better accuracy. This approach is introduced in the fast.ai &lt;a href="https://course.fast.ai/"&gt;Practical Deep Learning for Coders&lt;/a&gt; course &lt;a href="https://course.fast.ai/videos/?lesson=3"&gt;lesson 3&lt;/a&gt;.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Instead of training the model directly from a 256x256 image size, we’ll gradually scaling up the image size. More concretely, we will first train a &lt;span class="caps"&gt;CNN&lt;/span&gt; to classify the images of 128x128 size, once we achieved best accuracy, we’ll then use transfer learning and keep training the model on the same data-set, except with 256x256 image size. We’ll call the 128x128 image size training ‘stage 1’ and 256x256 image size training ‘stage&amp;nbsp;2’&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;After our stage 1 training(where my &lt;a href="https://medium.com/datadriveninvestor/deep-learning-models-by-fast-ai-library-c1cccc13e2b3"&gt;last post&lt;/a&gt; left off), we have a trained &lt;span class="caps"&gt;CNN&lt;/span&gt; model called learn , it’s ‘unfreezed’ and achieves an accuracy of around&amp;nbsp;85%.&lt;/p&gt;
&lt;p&gt;&lt;img alt="Accuracy 86% after training a 128x128 image size CNN." src="https://cdn-images-1.medium.com/max/2000/1*gereMOAvFIDiK2Mposxw4g.png"&gt;&lt;em&gt;Accuracy 86% after training a 128x128 image size &lt;span class="caps"&gt;CNN&lt;/span&gt;.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Now we need to freeze the network again, create a new ImageDataBunch with 256x256 image size and restart the same training&amp;nbsp;process.&lt;/p&gt;
&lt;p&gt;&lt;img alt="" src="https://cdn-images-1.medium.com/max/2000/1*uhQ8i6QTzLJQ1J9EwNtcsg.png"&gt;&lt;/p&gt;
&lt;p&gt;After finding the best learning rate, we train the &lt;span class="caps"&gt;CNN&lt;/span&gt; with another 2 epochs, already breaking into 91% accuracy. We’ll then do the same ‘unfreeze’ and keep&amp;nbsp;training.&lt;/p&gt;
&lt;p&gt;&lt;img alt="" src="https://cdn-images-1.medium.com/max/2000/1*CAwRb2bFZFpgTe8u5UA9JQ.png"&gt;&lt;/p&gt;
&lt;p&gt;After unfreeze, we trained the model with another 4 epochs, the accuracy broke into &lt;strong&gt;96.5%&lt;/strong&gt;. Observed that valudation_losshas already surpassed training_loss, suggesting a sign of overfitting. We’ll stop our training&amp;nbsp;here.&lt;/p&gt;
&lt;p&gt;This simple technique is also called ‘&lt;strong&gt;Progressive resizing&lt;/strong&gt;’ by &lt;a href="undefined"&gt;Jeremy Howard&lt;/a&gt; from &lt;a href="https://www.fast.ai/2018/08/10/fastai-diu-imagenet/"&gt;fast.ai&lt;/a&gt; and helped his team &lt;a href="https://www.theverge.com/2018/5/7/17316010/fast-ai-speed-test-stanford-dawnbench-google-intel"&gt;beat Google in a competition of speed training &lt;span class="caps"&gt;IMAGENET&lt;/span&gt; in *DAWNBench&lt;/a&gt; by training the &lt;span class="caps"&gt;IMAGGNET&lt;/span&gt; in a whopping&lt;strong&gt;18&lt;/strong&gt; minutes and &lt;strong&gt;\$40&lt;/strong&gt; Amazon &lt;span class="caps"&gt;AWS&lt;/span&gt;&amp;nbsp;cost.*&lt;/p&gt;
&lt;h3&gt;To Wrap It&amp;nbsp;Up&lt;/h3&gt;
&lt;p&gt;&lt;img alt="Photo by Franki Chamaki on Unsplash" src="https://cdn-images-1.medium.com/max/8064/0*ccqj05oUPQjsG_Jk"&gt;&lt;em&gt;Photo by &lt;a href="https://unsplash.com/@franki?utm_source=medium&amp;amp;utm_medium=referral"&gt;Franki Chamaki&lt;/a&gt; on &lt;a href="https://unsplash.com?utm_source=medium&amp;amp;utm_medium=referral"&gt;Unsplash&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;With two simple tweaks, we managed to increase the accuracy around 6.5%, breaking into the state-of-the-art range of results. Major&amp;nbsp;takeaways:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;When doing image pre-processing, make sure the processed images still properly represent what real-life data will look&amp;nbsp;like.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;The reason gradually increase training image size works is: by giving the trained model a data-set that’s 4 times bigger, actually means giving the model a brand new data to train, avoiding&amp;nbsp;overfitting.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Starting from smaller sized images for training will also have the benefit of faster training and quicker experimenting. This usually leads to better&amp;nbsp;results.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;That’s it for Chinese Calligraphy Classifier. I hope you learned a thing or two after reading these two articles. We’re trying to get some specific calligrapher’s ‘true’ and ‘fake’ artworks and see if we can build a ‘true or false’ classifier. This will be a very interesting and much valuable next step. Will report back and write more articles if we made real progress. But until then, we’ll move on to put this well-trained model into production and build a web-app around it. Stay&amp;nbsp;tuned.&lt;/p&gt;
&lt;p&gt;If you haven’t read my first post on this topic, here’s the link:
&lt;a href="https://medium.com/datadriveninvestor/deep-learning-models-by-fast-ai-library-c1cccc13e2b3"&gt;&lt;strong&gt;How I Trained Computer to Learn Calligraphy Styles: Part1&lt;/strong&gt;
&lt;em&gt;Build a Deep Learning Model with fast.ai Library&lt;/em&gt;medium.com&lt;/a&gt;&lt;/p&gt;</content><category term="Machine Learning"></category><category term="AI"></category><category term="Deep Learning"></category><category term="fast.ai"></category><category term="calligraphy"></category></entry><entry><title>Types of Optimization Algorithms used in Neural Networks and Ways to Optimize Gradient Descent</title><link href="https://wayofnumbers.github.io/Typtes-of-optimization-algorithms.html" rel="alternate"></link><published>2018-02-26T17:00:00-06:00</published><updated>2018-02-26T17:00:00-06:00</updated><author><name>Internet</name></author><id>tag:wayofnumbers.github.io,2018-02-26:/Typtes-of-optimization-algorithms.html</id><summary type="html">&lt;p&gt;Types of Optimization Algorithms used in Neural Networks and Ways to Optimize Gradient&amp;nbsp;Descent&lt;/p&gt;</summary><content type="html">&lt;p&gt;&lt;a href="https://towardsdatascience.com/types-of-optimization-algorithms-used-in-neural-networks-and-ways-to-optimize-gradient-95ae5d39529f"&gt;&lt;strong&gt;Original&amp;nbsp;Story&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="https://towardsdatascience.com/@anishsingh20"&gt;Anish Singh Walia&lt;/a&gt;:        &lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;If your input data is sparse then methods such as &lt;strong&gt;&lt;span class="caps"&gt;SGD&lt;/span&gt;,&lt;span class="caps"&gt;NAG&lt;/span&gt; and momentum&lt;/strong&gt; are inferior and perform poorly. &lt;strong&gt;For sparse data sets one should use one of the adaptive learning-rate methods.&lt;/strong&gt; An additional benefit is that we won’t need to adjust the learning rate but likely achieve the best results with the default value.
If one wants fast convergence and train a deep Neural Network Model or a highly complex Neural Network then &lt;strong&gt;Adam or any other Adaptive learning rate techniques&lt;/strong&gt; should be used because they outperforms every other optimization&amp;nbsp;algorithms.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;One thing about Machine Learning the overal depth of the topics and algorithms makes it so easy to totally &lt;em&gt;&amp;#8216;sink&amp;#8217;&lt;/em&gt; yourself into it. And there is always something to dig. This article provides a view from a higher ground and compare different optimization algorithms and their application areas, thus pulling you out of the deep hole of deep&amp;nbsp;learning. &lt;/p&gt;
&lt;p&gt;A more visual example of these algorithms, see these two beautifully crafted&amp;nbsp;animations:&lt;/p&gt;
&lt;p&gt;&lt;img alt="SGD optimization on loss surface contours" src="https://wayofnumbers.github.io/images/optimization-algorithem-1.gif" title="SGD optimization on loss surface contours"&gt;
&lt;div style="text-align: center;"&gt;&lt;span class="caps"&gt;SGD&lt;/span&gt; optimization on loss surface contours&lt;/div&gt;
&lt;br&gt;&lt;/p&gt;
&lt;p&gt;&lt;img alt="SGD optimization on saddle point" src="https://wayofnumbers.github.io/images/optimization-algorithem-2.gif" title="SGD optimization on saddle point"&gt;
&lt;div style="text-align: center;"&gt;&lt;span class="caps"&gt;SGD&lt;/span&gt; optimization on saddle point&lt;/div&gt;&lt;/p&gt;</content><category term="machinelearning"></category><category term="AI"></category><category term="Optimization Algorithm"></category><category term="Gradient Descent"></category><category term="Neural Networks"></category></entry><entry><title>Tweaking Pelican Elegant Theme</title><link href="https://wayofnumbers.github.io/Tweak-Pelican-Elegant-Theme.html" rel="alternate"></link><published>2018-02-24T20:00:00-06:00</published><updated>2018-02-24T20:00:00-06:00</updated><author><name>Michael Li</name></author><id>tag:wayofnumbers.github.io,2018-02-24:/Tweak-Pelican-Elegant-Theme.html</id><summary type="html">&lt;p&gt;My notes on how to tweak a Pelican theme, in this article,&amp;nbsp;Elegant.&lt;/p&gt;</summary><content type="html">&lt;p&gt;[&lt;span class="caps"&gt;TOC&lt;/span&gt;]&lt;/p&gt;
&lt;p&gt;&lt;img alt="Elegant" src="https://wayofnumbers.github.io/images/Elegant.png"&gt;&lt;/p&gt;
&lt;p&gt;Pelican has a lot of themes, developed by the community and shared on its official GitHub repo &lt;a href="https://github.com/getpelican/pelican-themes"&gt;here&lt;/a&gt;. &lt;a href="http://www.pelicanthemes.com/"&gt;Pelican Themes&lt;/a&gt; also offer some previews of them so you can have a good idea of what to expect. 
Some themes are really easy to setup and configure, others need some efforts. The &lt;a href="http://oncrashreboot.com/elegant-best-pelican-theme-features"&gt;Elegant&lt;/a&gt; them is the latter. For most of the themes, to make it work, you just need to add define the &amp;#8216;&lt;span class="caps"&gt;THEME&lt;/span&gt;&amp;#8217; variable, like&amp;nbsp;so:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;THEME&amp;#39;&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;theme/themename&amp;#39;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;For Elegant, it&amp;#8217;s way more than that, and it&amp;#8217;s a good thing. Elegant packed a lot of great features and thorough considerations to the reader. And that&amp;#8217;s why I choose it as the theme for my site. Good things come with a price they say. So let&amp;#8217;s find&amp;nbsp;out. &lt;/p&gt;
&lt;h2&gt;Search&lt;/h2&gt;
&lt;p&gt;Search is useful when you have a lot of articles. All serious blog need to have it. To use it, add &amp;#8216;tipue_search&amp;#8217; and &amp;#8216;sitemap&amp;#8217; to your plugins and it will automatically be&amp;nbsp;enabled. &lt;/p&gt;
&lt;h2&gt;About Me and My&amp;nbsp;Project&lt;/h2&gt;
&lt;p&gt;Elegant&amp;#8217;s home page layout put the blogger himself front and center with &amp;#8216;About Me&amp;#8217; and the &amp;#8216;My Project&amp;#8217; at the top, followed with &amp;#8216;Recent Posts&amp;#8217;. To use them, you need to set the &amp;#8216;LANDING_PAGE_ABOUT&amp;#8217; and &amp;#8216;&lt;span class="caps"&gt;PROJECTS&lt;/span&gt;&amp;#8217; variables in the &lt;code&gt;pelicanconf.py&lt;/code&gt;. &lt;/p&gt;
&lt;h2&gt;jQuery&amp;nbsp;Issue&lt;/h2&gt;
&lt;p&gt;I&amp;#8217;ve enabled all the nice features, like search, collasible comments, collasible comments. But they all won&amp;#8217;t work on Chrome because it&amp;#8217;s considered &amp;#8216;unsafe scripts&amp;#8217;. After some digging, it turns out the site is using &lt;span class="caps"&gt;HTTPS&lt;/span&gt;, while the original theme&amp;#8217;s template uses &lt;span class="caps"&gt;HTTP&lt;/span&gt; to load the jQuery that did all these nice features. Once I replaced the &lt;span class="caps"&gt;HTTP&lt;/span&gt; with its &lt;span class="caps"&gt;HTTPS&lt;/span&gt; counterpart, everything works like a&amp;nbsp;charm. &lt;/p&gt;
&lt;h2&gt;Table of&amp;nbsp;Contents&lt;/h2&gt;
&lt;p&gt;Took me some time to get table of contents to work. Firstly &amp;#8216;extract_toc&amp;#8217; plugin needs to be added into the &amp;#8216;&lt;span class="caps"&gt;PLUGINS&lt;/span&gt;&amp;#8217; variable. Then &amp;#8216;markdown&amp;#8217; Python module needs to be installed and configured for it to work as the Elegant website instructions. But after all this, it still didn&amp;#8217;t work. Turns out, you need to add &lt;code&gt;[TOC]&lt;/code&gt; in the Markdown file, after all the meta data, to actually add the table of contents into your post. After I did that, everything&amp;nbsp;works. &lt;/p&gt;
&lt;h2&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;Install and tweaking a Pelican theme isn&amp;#8217;t that hard. Look into the static folder for &lt;span class="caps"&gt;CSS&lt;/span&gt;, tweak them if you want, or add custom &lt;span class="caps"&gt;CSS&lt;/span&gt; of your own and load them in the template. Then go into the template folder to check the html files. With basic &lt;span class="caps"&gt;HTML&lt;/span&gt;/&lt;span class="caps"&gt;CSS&lt;/span&gt;/Javascripts knowledge, you already can achieve a lot on tweaking any theme of your&amp;nbsp;liking. &lt;/p&gt;</content><category term="Pelican"></category><category term="Blog"></category><category term="Github"></category><category term="Theme"></category></entry><entry><title>The AI Shortage</title><link href="https://wayofnumbers.github.io/The-AI-Shortage.html" rel="alternate"></link><published>2018-02-23T17:00:00-06:00</published><updated>2018-02-23T17:00:00-06:00</updated><author><name>Internet</name></author><id>tag:wayofnumbers.github.io,2018-02-23:/The-AI-Shortage.html</id><summary type="html">&lt;p&gt;&lt;span class="caps"&gt;AI&lt;/span&gt; talent shortage is not getting better any time&amp;nbsp;soon&amp;#8230;&lt;/p&gt;</summary><content type="html">&lt;p&gt;&lt;a href="https://medium.com/@Moscow25/the-ai-talent-shortage-704d8cf0c4cc"&gt;&lt;strong&gt;Original&amp;nbsp;Story&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="https://medium.com/@Moscow25"&gt;Nikolai Yakovenko&lt;/a&gt; from &lt;span class="caps"&gt;NVIDIA&lt;/span&gt;:        &lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;But when I look for a designer, a Java developer, a real estate agent, etc — some are way better than others and deserve to get paid more than an &lt;span class="caps"&gt;AI&lt;/span&gt; researcher — but you’re fundamentally talking about pulling from a large well-balanced pool. It’s mostly an information game, and a matter of getting a little better than you need, but not much more than you can afford or should be paying.
In &lt;span class="caps"&gt;AI&lt;/span&gt;, it’s different. There just aren’t enough people to go around. And there aren’t enough people for every good project that can be attempted. Either academic, or something that if it works, can save the company&amp;nbsp;$1M.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;The booming of a new disruptive technology always did this to the industry as well as the talent pool. It drives money into investing on the next big thing, and the money lures more talents into the field. There will be a shortage in the very beginning, and there will always be a surplus at the end of the curve. I&amp;#8217;m afraid &lt;span class="caps"&gt;AI&lt;/span&gt; won&amp;#8217;t be any different. It&amp;#8217;s just that the curve will take 10 maybe more years to unfold so it&amp;#8217;s not too late to get in the game if you think you have the stuff, since at the end of day, people with talent and grit will win, in every new technology &amp;#8216;gold&amp;nbsp;rush&amp;#8217;. &lt;/p&gt;</content><category term="machinelearning"></category><category term="AI"></category></entry><entry><title>Setup Data Science Blog with Pelican + GitHub Pages</title><link href="https://wayofnumbers.github.io/Setup-Pelican-1.html" rel="alternate"></link><published>2018-02-14T20:00:00-06:00</published><updated>2018-02-14T20:00:00-06:00</updated><author><name>Michael Li</name></author><id>tag:wayofnumbers.github.io,2018-02-14:/Setup-Pelican-1.html</id><summary type="html">&lt;p&gt;My notes on how to setup Data Science blog using Pelican static site generater and GitHub&amp;nbsp;Pages.&lt;/p&gt;</summary><content type="html">&lt;p&gt;[&lt;span class="caps"&gt;TOC&lt;/span&gt;]&lt;/p&gt;
&lt;p&gt;&lt;img alt="Coding Background" src="https://wayofnumbers.github.io/images/coding.png"&gt;&lt;/p&gt;
&lt;p&gt;First of all, this is by no means a thorough tutorial. I&amp;#8217;ve followed Dataquest&amp;#8217;s blog post: &lt;a href="https://www.dataquest.io/blog/how-to-setup-a-data-science-blog/"&gt;Building a data science portfolio: Making a data science blog&lt;/a&gt; to get this one setup. Here are some insights and hiccups that may be helpful to others who want to do the same&amp;nbsp;thing.&lt;/p&gt;
&lt;h2&gt;Static sites and static sites&amp;nbsp;generator&lt;/h2&gt;
&lt;p&gt;If you have never experienced the web development world, static site might be a new word to you. Actually it&amp;#8217;s quite simple, it&amp;#8217;s just plan web-site with &lt;span class="caps"&gt;HTML&lt;/span&gt; files, &lt;span class="caps"&gt;CSS&lt;/span&gt; sheets and Javascript files. These file never changes unless you make them, thus the word &amp;#8216;static&amp;#8217;. The &amp;#8216;dynamic&amp;#8217; site, on the other hand, use database and complex post-end technology to &amp;#8216;dynamically&amp;#8217; generate these &lt;span class="caps"&gt;HTML&lt;/span&gt;/&lt;span class="caps"&gt;CSS&lt;/span&gt;/Javascripts files. It&amp;#8217;s much harder to develop and maintain. 
But I don&amp;#8217;t want that complexity you say. I just want to write something and post them and make them look neat. Then, my friend, look no further than a static site. Good news to us, there are a lot of static sites generators out there that can help us do the heavy-lifting of developing a website. 
The static sites generators come with many flavors, &lt;a href="https://jekyllrb.com/"&gt;Jekyell(based on Ruby)&lt;/a&gt;, &lt;a href="https://blog.getpelican.com/"&gt;Pelican(based on Python&lt;/a&gt; are too popular one. Since I&amp;#8217;m more familiar with Python. I decided to use Pelican to build my data science&amp;nbsp;blog.&lt;/p&gt;
&lt;p&gt;The beautiful thing here is, since Pelican is written in Python, it&amp;#8217;s quite easy to make it work with Jupyter Notebook, which is a huge bonus for data science. This means you can write your blog posts using Jupyter Notebook, leverage all the powerful snippets, data visualization and code executing it has and roll all those into your post, with&amp;nbsp;ease.&lt;/p&gt;
&lt;h2&gt;Install&amp;nbsp;Pelican&lt;/h2&gt;
&lt;p&gt;Usually install Pelican will be easy, but if we also want to support Jupyter Notebook it will be harder. Many python modules will need to be installed using &lt;strong&gt;pip&lt;/strong&gt;. &lt;/p&gt;
&lt;p&gt;Here is a list I&amp;nbsp;used:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="nv"&gt;Markdown&lt;/span&gt;&lt;span class="o"&gt;==&lt;/span&gt;&lt;span class="m"&gt;2&lt;/span&gt;.6.6    &lt;span class="c1"&gt;# Markdown support&lt;/span&gt;
&lt;span class="nv"&gt;pelican&lt;/span&gt;&lt;span class="o"&gt;==&lt;/span&gt;&lt;span class="m"&gt;3&lt;/span&gt;.6.3     &lt;span class="c1"&gt;# Pelican itself&lt;/span&gt;
jupyter&amp;gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;1&lt;/span&gt;.0       &lt;span class="c1"&gt;# Jupyter Notebook&lt;/span&gt;
ipython&amp;gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;4&lt;/span&gt;.0       &lt;span class="c1"&gt;# iPython&lt;/span&gt;
nbconvert&amp;gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;4&lt;/span&gt;.0     &lt;span class="c1"&gt;#&lt;/span&gt;
beautifulsoup4     &lt;span class="c1"&gt;# not sure why we need pharsing here, maybe manipulating codes&lt;/span&gt;
ghp-import&lt;span class="o"&gt;==&lt;/span&gt;&lt;span class="m"&gt;0&lt;/span&gt;.4.1  &lt;span class="c1"&gt;#handle git branches&lt;/span&gt;
&lt;span class="nv"&gt;matplotlib&lt;/span&gt;&lt;span class="o"&gt;==&lt;/span&gt;&lt;span class="m"&gt;1&lt;/span&gt;.5.1  &lt;span class="c1"&gt;#data visualization&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Once all are installed,&amp;nbsp;run:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;pelican-quickstart
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Answer couple of questions and the backbone of your site is up. To make the Jupyter Notebook part work, we will need this Pelican plugin (yes, Pelican support plugins!): &lt;a href="https://github.com/danielfrg/pelican-ipynb"&gt;Pelican-ipynb&lt;/a&gt;. 
Once installed, activate the plugin in your &lt;code&gt;pelicanconf.py&lt;/code&gt;. This is your dot file, and you&amp;#8217;ll be dealig with it a lot later on. 
Add these into the&amp;nbsp;bottom:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;MARKUP&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;md&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;ipynb&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="n"&gt;PLUGIN_PATH&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;./plugins&amp;#39;&lt;/span&gt;
&lt;span class="n"&gt;PLUGINS&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;ipynb.markup&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;h2&gt;Write&amp;nbsp;Post&lt;/h2&gt;
&lt;p&gt;Well this is the easier part. Just put your Jupyter Notebook file into the &lt;code&gt;'content'&lt;/code&gt; folder. Also, for each post, we&amp;#8217;ll need a meta file to include some meta data of the post. The meta file should have the extension: &lt;code&gt;.ipynb-meta&lt;/code&gt;. Here is an&amp;nbsp;example:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;Title&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="n"&gt;First&lt;/span&gt; &lt;span class="n"&gt;Post&lt;/span&gt;
&lt;span class="n"&gt;Slug&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="n"&gt;first&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;post&lt;/span&gt;
&lt;span class="n"&gt;Date&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="mi"&gt;2016&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;06&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;08&lt;/span&gt; &lt;span class="mi"&gt;20&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="mi"&gt;00&lt;/span&gt;
&lt;span class="n"&gt;Category&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="n"&gt;posts&lt;/span&gt;
&lt;span class="n"&gt;Tags&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="n"&gt;python&lt;/span&gt; &lt;span class="n"&gt;firsts&lt;/span&gt;
&lt;span class="n"&gt;author&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="n"&gt;Vik&lt;/span&gt; &lt;span class="n"&gt;Paruchuri&lt;/span&gt;
&lt;span class="n"&gt;Summary&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="n"&gt;My&lt;/span&gt; &lt;span class="n"&gt;first&lt;/span&gt; &lt;span class="n"&gt;post&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="n"&gt;read&lt;/span&gt; &lt;span class="n"&gt;it&lt;/span&gt; &lt;span class="n"&gt;to&lt;/span&gt; &lt;span class="n"&gt;find&lt;/span&gt; &lt;span class="n"&gt;out&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;It&amp;#8217;s quite easy to figure out what they are so I won&amp;#8217;t bother explain here. When done,&amp;nbsp;save. &lt;/p&gt;
&lt;h2&gt;Generating &lt;span class="caps"&gt;HTML&lt;/span&gt;&lt;/h2&gt;
&lt;p&gt;Exit out of content folder, and run &lt;code&gt;pelican content&lt;/code&gt; to generate the &lt;span class="caps"&gt;HTML&lt;/span&gt;. Enter &lt;code&gt;output&lt;/code&gt; again and&amp;nbsp;run:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;python -m pelican.server
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Then visit: &lt;code&gt;localhost:8000&lt;/code&gt; to see your new&amp;nbsp;site. &lt;/p&gt;
&lt;h2&gt;Putting it on GitHub&amp;nbsp;Pages&lt;/h2&gt;
&lt;p&gt;Create a GitHub Page is simple and there are many tutorials out there. Once created, edit your &lt;code&gt;SITEURL&lt;/code&gt; in &lt;code&gt;publishconf.py&lt;/code&gt; file, make it into &lt;code&gt;https://username.github.io&lt;/code&gt;, substitute &lt;code&gt;username&lt;/code&gt; with your site&amp;nbsp;name. &lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;Run &lt;code&gt;pelican content -s publishconf.py&lt;/code&gt; to generate the real&amp;nbsp;stuff. &lt;/p&gt;
&lt;p&gt;Run &lt;code&gt;ghp-import output -b master&lt;/code&gt; to import everything into the &lt;code&gt;output&lt;/code&gt; folder to the &lt;code&gt;master&lt;/code&gt; branch. &lt;/p&gt;
&lt;p&gt;Run &lt;code&gt;git push origin master&lt;/code&gt; to push changes to GitHub&amp;nbsp;repo. &lt;/p&gt;
&lt;hr&gt;
&lt;h2&gt;Themes&lt;/h2&gt;
&lt;p&gt;There are a lot of &lt;a href="https://github.com/getpelican/pelican-themes"&gt;themes&lt;/a&gt; to choose from. What you need to do is to configure your &lt;code&gt;pelicanconf.py&lt;/code&gt; file and assign the theme name. Some themes may need to install extra Python modules or have access to other services to work. But overall the process is straight&amp;nbsp;forward.&lt;/p&gt;
&lt;h2&gt;Google&amp;nbsp;Analytics&lt;/h2&gt;
&lt;p&gt;Pelican have Google Analytics support out of the box. Register the site on &lt;span class="caps"&gt;GA&lt;/span&gt;, then get the &lt;code&gt;UA-XXXXxxxxx&lt;/code&gt; id, put it into the &lt;code&gt;pelicanconf.py&lt;/code&gt; file and you&amp;#8217;re&amp;nbsp;golden. &lt;/p&gt;
&lt;h2&gt;Disqus&lt;/h2&gt;
&lt;p&gt;Disqus support come out of the box too. Register the site on Disqus, get your &lt;strong&gt;shortname&lt;/strong&gt; correct, and put into &lt;code&gt;pelicanconf.py&lt;/code&gt; and you should be good too. Some turorial suggest put into &lt;code&gt;publishconf.py&lt;/code&gt;, well mine only works on &lt;code&gt;pelicanconf.py&lt;/code&gt; so use your own&amp;nbsp;judgement. &lt;/p&gt;
&lt;h2&gt;&lt;span class="caps"&gt;SEO&lt;/span&gt;&lt;/h2&gt;
&lt;p&gt;Basic &lt;span class="caps"&gt;SEO&lt;/span&gt; can be achieved using &lt;strong&gt;sitemap&lt;/strong&gt; plugin. Search for it and put into &lt;code&gt;pelicanconf.py&lt;/code&gt;, it will work&amp;nbsp;automatically.&lt;/p&gt;
&lt;h2&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;Overall the process is not hard at all. Once everything is set. Just focus on putting in solid content using Jupyter Notebook. Enjoy coding, visualizing and&amp;nbsp;writing!&lt;/p&gt;</content><category term="Pelican"></category><category term="Data Science"></category><category term="Blog"></category><category term="Github"></category><category term="Jupyter Notebook"></category><category term="Disqus"></category><category term="Google Analytics"></category></entry></feed>