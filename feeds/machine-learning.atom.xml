<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>Way of Numbers - Machine Learning</title><link href="https://wayofnumbers.github.io/" rel="alternate"></link><link href="https://wayofnumbers.github.io/feeds/machine-learning.atom.xml" rel="self"></link><id>https://wayofnumbers.github.io/</id><updated>2019-09-16T20:00:00-05:00</updated><subtitle>Data science for the rest of us.</subtitle><entry><title>How I Trained Computer to Learn Calligraphy Styles: Part 2</title><link href="https://wayofnumbers.github.io/chinese-calligraphy-classifier-2.html" rel="alternate"></link><published>2019-09-16T20:00:00-05:00</published><updated>2019-09-16T20:00:00-05:00</updated><author><name>Michael Li</name></author><id>tag:wayofnumbers.github.io,2019-09-16:/chinese-calligraphy-classifier-2.html</id><summary type="html">&lt;p&gt;Fine-tune model for Chinese Calligraphy Classifier with fast.ai&amp;nbsp;library&lt;/p&gt;</summary><content type="html">&lt;p&gt;Build a Deep Learning Model with fast.ai&amp;nbsp;Library&lt;/p&gt;
&lt;p&gt;&lt;img alt="Photo by Kon Karampelas on Unsplash" src="https://cdn-images-1.medium.com/max/12000/0*gzpUfcpouuU10xO1"&gt;&lt;em&gt;Photo by &lt;a href="https://unsplash.com/@konkarampelas?utm_source=medium&amp;amp;utm_medium=referral"&gt;Kon Karampelas&lt;/a&gt; on &lt;a href="https://unsplash.com?utm_source=medium&amp;amp;utm_medium=referral"&gt;Unsplash&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;I wanted to start a series of posts for the projects I finished/polished for my &lt;a href="https://course.fast.ai/"&gt;Practical Deep Learning for Coders&lt;/a&gt; fast.ai course. Since I’m pretty green on &lt;span class="caps"&gt;ML&lt;/span&gt;/&lt;span class="caps"&gt;DL&lt;/span&gt; field, I hope the challenges I faced and overcome could be of value for other people experiencing the same&amp;nbsp;journey.&lt;/p&gt;
&lt;p&gt;Model &lt;a href="https://medium.com/@lymenlee/deep-learning-models-by-fast-ai-library-c1cccc13e2b3"&gt;1&lt;/a&gt; ・&lt;a href="https://medium.com/datadriveninvestor/chinese-calligraphy-classifier-fine-tuning-cbfbf0e304d8"&gt;1a&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;Making It Even&amp;nbsp;Better&lt;/h3&gt;
&lt;p&gt;In my &lt;a href="https://medium.com/datadriveninvestor/deep-learning-models-by-fast-ai-library-c1cccc13e2b3"&gt;last post&lt;/a&gt;, I explained the approach I take for this image recognition problem using fast.ai library. As you can see, once we get the data down to a fast.ai ImageDataBunch, the code is rather simple and we achieve a 90% accuracy rate, which is quite impressive considering the quality of our data(randomly downloaded from Google/Baidu search without much data cleaning). Now, can we do better?
&lt;a href="https://www.datadriveninvestor.com/2019/03/03/editors-pick-5-machine-learning-books/"&gt;&lt;strong&gt;&lt;span class="caps"&gt;DDI&lt;/span&gt; Editor&amp;#8217;s Pick: 5 Machine Learning Books That Turn You from Novice to Expert | Data Driven…&lt;/strong&gt;
&lt;em&gt;The booming growth in the Machine Learning industry has brought renewed interest in people about Artificial…&lt;/em&gt;www.datadriveninvestor.com&lt;/a&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;h1&gt;Turns out, we&amp;nbsp;can!&lt;/h1&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;img alt="" src="https://cdn-images-1.medium.com/max/2000/1*sz46EDt2HU_N2YecCXJ9ng.jpeg"&gt;&lt;/p&gt;
&lt;p&gt;How? Well, there are two things in our prior pipeline that could&amp;nbsp;improve:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Image Pre-processing&amp;nbsp;Tweak&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Model Training Fine&amp;nbsp;Tune.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Let’s dive&amp;nbsp;deeper.&lt;/p&gt;
&lt;h3&gt;Image Pre-Processing&amp;nbsp;Tweak&lt;/h3&gt;
&lt;p&gt;Remember when we import our data into fast.ai ImageDataBunch, we used the following&amp;nbsp;code:&lt;/p&gt;
&lt;p&gt;&lt;img alt="" src="https://cdn-images-1.medium.com/max/2000/0*Prt5fbhL-qj1OoQE.png"&gt;&lt;/p&gt;
&lt;p&gt;Notice that on our image pre-processing, i.e. get_transforms function, we didn’t give it any parameter and just used the default. The default will try to apply a variety of image augmentation techniques to make the image data-set generalize better, like flipping, warping, rotating, cropping, etc. This is good, fast.ai library helped us do the ‘best practice’ for the majority of the cases. But in our case here, some default might not work that&amp;nbsp;well.&lt;/p&gt;
&lt;p&gt;The biggest one is ‘flipping’. Because we are trying to classify calligraphy artworks and in real life, it will never randomly flip left/right or up/down. So making the images flips randomly will not reflect the real-life cases and thus won’t help with our training&amp;nbsp;accuracy.&lt;/p&gt;
&lt;p&gt;To fix this, we tweaked our code as&amp;nbsp;below:&lt;/p&gt;
&lt;p&gt;&lt;img alt="" src="https://cdn-images-1.medium.com/max/2000/1*9Gv0vDlF12MPKznehyU1LA.png"&gt;&lt;/p&gt;
&lt;p&gt;Notice we pass do_flip=False into the get_transforms function, thus telling the module to not randomly flipping our images during&amp;nbsp;importing.&lt;/p&gt;
&lt;h3&gt;Model Training Fine&amp;nbsp;Tune&lt;/h3&gt;
&lt;p&gt;Now that the image pre-processing is done. We can re-structure out model training to avoid overfitting and achieve better accuracy. This approach is introduced in the fast.ai &lt;a href="https://course.fast.ai/"&gt;Practical Deep Learning for Coders&lt;/a&gt; course &lt;a href="https://course.fast.ai/videos/?lesson=3"&gt;lesson 3&lt;/a&gt;.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Instead of training the model directly from a 256x256 image size, we’ll gradually scaling up the image size. More concretely, we will first train a &lt;span class="caps"&gt;CNN&lt;/span&gt; to classify the images of 128x128 size, once we achieved best accuracy, we’ll then use transfer learning and keep training the model on the same data-set, except with 256x256 image size. We’ll call the 128x128 image size training ‘stage 1’ and 256x256 image size training ‘stage&amp;nbsp;2’&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;After our stage 1 training(where my &lt;a href="https://medium.com/datadriveninvestor/deep-learning-models-by-fast-ai-library-c1cccc13e2b3"&gt;last post&lt;/a&gt; left off), we have a trained &lt;span class="caps"&gt;CNN&lt;/span&gt; model called learn , it’s ‘unfreezed’ and achieves an accuracy of around&amp;nbsp;85%.&lt;/p&gt;
&lt;p&gt;&lt;img alt="Accuracy 86% after training a 128x128 image size CNN." src="https://cdn-images-1.medium.com/max/2000/1*gereMOAvFIDiK2Mposxw4g.png"&gt;&lt;em&gt;Accuracy 86% after training a 128x128 image size &lt;span class="caps"&gt;CNN&lt;/span&gt;.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Now we need to freeze the network again, create a new ImageDataBunch with 256x256 image size and restart the same training&amp;nbsp;process.&lt;/p&gt;
&lt;p&gt;&lt;img alt="" src="https://cdn-images-1.medium.com/max/2000/1*uhQ8i6QTzLJQ1J9EwNtcsg.png"&gt;&lt;/p&gt;
&lt;p&gt;After finding the best learning rate, we train the &lt;span class="caps"&gt;CNN&lt;/span&gt; with another 2 epochs, already breaking into 91% accuracy. We’ll then do the same ‘unfreeze’ and keep&amp;nbsp;training.&lt;/p&gt;
&lt;p&gt;&lt;img alt="" src="https://cdn-images-1.medium.com/max/2000/1*CAwRb2bFZFpgTe8u5UA9JQ.png"&gt;&lt;/p&gt;
&lt;p&gt;After unfreeze, we trained the model with another 4 epochs, the accuracy broke into &lt;strong&gt;96.5%&lt;/strong&gt;. Observed that valudation_losshas already surpassed training_loss, suggesting a sign of overfitting. We’ll stop our training&amp;nbsp;here.&lt;/p&gt;
&lt;p&gt;This simple technique is also called ‘&lt;strong&gt;Progressive resizing&lt;/strong&gt;’ by &lt;a href="undefined"&gt;Jeremy Howard&lt;/a&gt; from &lt;a href="https://www.fast.ai/2018/08/10/fastai-diu-imagenet/"&gt;fast.ai&lt;/a&gt; and helped his team &lt;a href="https://www.theverge.com/2018/5/7/17316010/fast-ai-speed-test-stanford-dawnbench-google-intel"&gt;beat Google in a competition of speed training &lt;span class="caps"&gt;IMAGENET&lt;/span&gt; in *DAWNBench&lt;/a&gt; by training the &lt;span class="caps"&gt;IMAGGNET&lt;/span&gt; in a whopping&lt;strong&gt;18&lt;/strong&gt; minutes and &lt;strong&gt;\$40&lt;/strong&gt; Amazon &lt;span class="caps"&gt;AWS&lt;/span&gt;&amp;nbsp;cost.*&lt;/p&gt;
&lt;h3&gt;To Wrap It&amp;nbsp;Up&lt;/h3&gt;
&lt;p&gt;&lt;img alt="Photo by Franki Chamaki on Unsplash" src="https://cdn-images-1.medium.com/max/8064/0*ccqj05oUPQjsG_Jk"&gt;&lt;em&gt;Photo by &lt;a href="https://unsplash.com/@franki?utm_source=medium&amp;amp;utm_medium=referral"&gt;Franki Chamaki&lt;/a&gt; on &lt;a href="https://unsplash.com?utm_source=medium&amp;amp;utm_medium=referral"&gt;Unsplash&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;With two simple tweaks, we managed to increase the accuracy around 6.5%, breaking into the state-of-the-art range of results. Major&amp;nbsp;takeaways:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;When doing image pre-processing, make sure the processed images still properly represent what real-life data will look&amp;nbsp;like.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;The reason gradually increase training image size works is: by giving the trained model a data-set that’s 4 times bigger, actually means giving the model a brand new data to train, avoiding&amp;nbsp;overfitting.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Starting from smaller sized images for training will also have the benefit of faster training and quicker experimenting. This usually leads to better&amp;nbsp;results.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;That’s it for Chinese Calligraphy Classifier. I hope you learned a thing or two after reading these two articles. We’re trying to get some specific calligrapher’s ‘true’ and ‘fake’ artworks and see if we can build a ‘true or false’ classifier. This will be a very interesting and much valuable next step. Will report back and write more articles if we made real progress. But until then, we’ll move on to put this well-trained model into production and build a web-app around it. Stay&amp;nbsp;tuned.&lt;/p&gt;
&lt;p&gt;If you haven’t read my first post on this topic, here’s the link:
&lt;a href="https://medium.com/datadriveninvestor/deep-learning-models-by-fast-ai-library-c1cccc13e2b3"&gt;&lt;strong&gt;How I Trained Computer to Learn Calligraphy Styles: Part1&lt;/strong&gt;
&lt;em&gt;Build a Deep Learning Model with fast.ai Library&lt;/em&gt;medium.com&lt;/a&gt;&lt;/p&gt;</content><category term="Machine Learning"></category><category term="AI"></category><category term="Deep Learning"></category><category term="fast.ai"></category><category term="calligraphy"></category></entry><entry><title>Types of Optimization Algorithms used in Neural Networks and Ways to Optimize Gradient Descent</title><link href="https://wayofnumbers.github.io/Typtes-of-optimization-algorithms.html" rel="alternate"></link><published>2018-02-26T17:00:00-06:00</published><updated>2018-02-26T17:00:00-06:00</updated><author><name>Internet</name></author><id>tag:wayofnumbers.github.io,2018-02-26:/Typtes-of-optimization-algorithms.html</id><summary type="html">&lt;p&gt;Types of Optimization Algorithms used in Neural Networks and Ways to Optimize Gradient&amp;nbsp;Descent&lt;/p&gt;</summary><content type="html">&lt;p&gt;&lt;a href="https://towardsdatascience.com/types-of-optimization-algorithms-used-in-neural-networks-and-ways-to-optimize-gradient-95ae5d39529f"&gt;&lt;strong&gt;Original&amp;nbsp;Story&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="https://towardsdatascience.com/@anishsingh20"&gt;Anish Singh Walia&lt;/a&gt;:        &lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;If your input data is sparse then methods such as &lt;strong&gt;&lt;span class="caps"&gt;SGD&lt;/span&gt;,&lt;span class="caps"&gt;NAG&lt;/span&gt; and momentum&lt;/strong&gt; are inferior and perform poorly. &lt;strong&gt;For sparse data sets one should use one of the adaptive learning-rate methods.&lt;/strong&gt; An additional benefit is that we won’t need to adjust the learning rate but likely achieve the best results with the default value.
If one wants fast convergence and train a deep Neural Network Model or a highly complex Neural Network then &lt;strong&gt;Adam or any other Adaptive learning rate techniques&lt;/strong&gt; should be used because they outperforms every other optimization&amp;nbsp;algorithms.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;One thing about Machine Learning the overal depth of the topics and algorithms makes it so easy to totally &lt;em&gt;&amp;#8216;sink&amp;#8217;&lt;/em&gt; yourself into it. And there is always something to dig. This article provides a view from a higher ground and compare different optimization algorithms and their application areas, thus pulling you out of the deep hole of deep&amp;nbsp;learning. &lt;/p&gt;
&lt;p&gt;A more visual example of these algorithms, see these two beautifully crafted&amp;nbsp;animations:&lt;/p&gt;
&lt;p&gt;&lt;img alt="SGD optimization on loss surface contours" src="https://wayofnumbers.github.io/images/optimization-algorithem-1.gif" title="SGD optimization on loss surface contours"&gt;
&lt;div style="text-align: center;"&gt;&lt;span class="caps"&gt;SGD&lt;/span&gt; optimization on loss surface contours&lt;/div&gt;
&lt;br&gt;&lt;/p&gt;
&lt;p&gt;&lt;img alt="SGD optimization on saddle point" src="https://wayofnumbers.github.io/images/optimization-algorithem-2.gif" title="SGD optimization on saddle point"&gt;
&lt;div style="text-align: center;"&gt;&lt;span class="caps"&gt;SGD&lt;/span&gt; optimization on saddle point&lt;/div&gt;&lt;/p&gt;</content><category term="machinelearning"></category><category term="AI"></category><category term="Optimization Algorithm"></category><category term="Gradient Descent"></category><category term="Neural Networks"></category></entry><entry><title>The AI Shortage</title><link href="https://wayofnumbers.github.io/The-AI-Shortage.html" rel="alternate"></link><published>2018-02-23T17:00:00-06:00</published><updated>2018-02-23T17:00:00-06:00</updated><author><name>Internet</name></author><id>tag:wayofnumbers.github.io,2018-02-23:/The-AI-Shortage.html</id><summary type="html">&lt;p&gt;&lt;span class="caps"&gt;AI&lt;/span&gt; talent shortage is not getting better any time&amp;nbsp;soon&amp;#8230;&lt;/p&gt;</summary><content type="html">&lt;p&gt;&lt;a href="https://medium.com/@Moscow25/the-ai-talent-shortage-704d8cf0c4cc"&gt;&lt;strong&gt;Original&amp;nbsp;Story&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="https://medium.com/@Moscow25"&gt;Nikolai Yakovenko&lt;/a&gt; from &lt;span class="caps"&gt;NVIDIA&lt;/span&gt;:        &lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;But when I look for a designer, a Java developer, a real estate agent, etc — some are way better than others and deserve to get paid more than an &lt;span class="caps"&gt;AI&lt;/span&gt; researcher — but you’re fundamentally talking about pulling from a large well-balanced pool. It’s mostly an information game, and a matter of getting a little better than you need, but not much more than you can afford or should be paying.
In &lt;span class="caps"&gt;AI&lt;/span&gt;, it’s different. There just aren’t enough people to go around. And there aren’t enough people for every good project that can be attempted. Either academic, or something that if it works, can save the company&amp;nbsp;$1M.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;The booming of a new disruptive technology always did this to the industry as well as the talent pool. It drives money into investing on the next big thing, and the money lures more talents into the field. There will be a shortage in the very beginning, and there will always be a surplus at the end of the curve. I&amp;#8217;m afraid &lt;span class="caps"&gt;AI&lt;/span&gt; won&amp;#8217;t be any different. It&amp;#8217;s just that the curve will take 10 maybe more years to unfold so it&amp;#8217;s not too late to get in the game if you think you have the stuff, since at the end of day, people with talent and grit will win, in every new technology &amp;#8216;gold&amp;nbsp;rush&amp;#8217;. &lt;/p&gt;</content><category term="machinelearning"></category><category term="AI"></category></entry></feed>