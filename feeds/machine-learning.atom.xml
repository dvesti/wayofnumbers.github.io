<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>Way of Numbers - Machine Learning</title><link href="https://wayofnumbers.github.io/" rel="alternate"></link><link href="https://wayofnumbers.github.io/feeds/machine-learning.atom.xml" rel="self"></link><id>https://wayofnumbers.github.io/</id><updated>2019-09-11T00:00:00-05:00</updated><subtitle>Data science for the rest of us.</subtitle><entry><title>Deep Learning Models : Chinese Calligraphy Classifier by fast.ai¬†Library</title><link href="https://wayofnumbers.github.io/deep-learning-models-chinese-calligraphy-classifier-by-fastai.html" rel="alternate"></link><published>2019-09-11T00:00:00-05:00</published><updated>2019-09-11T00:00:00-05:00</updated><author><name>Michael Li</name></author><id>tag:wayofnumbers.github.io,2019-09-11:/deep-learning-models-chinese-calligraphy-classifier-by-fastai.html</id><summary type="html">&lt;p&gt;I wanted to start a series of posts for the projects I finished/polished for my Practical Deep Learning for Coders fast.ai course. Since I‚Äôm pretty green on &lt;span class="caps"&gt;ML&lt;/span&gt;/&lt;span class="caps"&gt;DL&lt;/span&gt; field, I hope the challenges I faced and overcome could be of value for other people experiencing the same&amp;nbsp;journey.&lt;/p&gt;</summary><content type="html">&lt;h1&gt;Deep Learning Models by fast.ai&amp;nbsp;Library&lt;/h1&gt;
&lt;p&gt;1 Chinese Calligraphy&amp;nbsp;Classifier&lt;/p&gt;
&lt;p&gt;&lt;img alt="Photo by Raychan on Unsplash" src="https://cdn-images-1.medium.com/max/10944/0*1vRfrkhsQiTkkBgJ"&gt;&lt;em&gt;Photo by &lt;a href="https://unsplash.com/@wx1993?utm_source=medium&amp;amp;utm_medium=referral"&gt;Raychan&lt;/a&gt; on &lt;a href="https://unsplash.com?utm_source=medium&amp;amp;utm_medium=referral"&gt;Unsplash&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;I wanted to start a series of posts for the projects I finished/polished for my &lt;a href="https://course.fast.ai/"&gt;Practical Deep Learning for Coders&lt;/a&gt; fast.ai course. Since I‚Äôm pretty green on &lt;span class="caps"&gt;ML&lt;/span&gt;/&lt;span class="caps"&gt;DL&lt;/span&gt; field, I hope the challenges I faced and overcome could be of value for other people experiencing the same&amp;nbsp;journey.&lt;/p&gt;
&lt;p&gt;Model &lt;a href="https://medium.com/@lymenlee/deep-learning-models-by-fast-ai-library-c1cccc13e2b3"&gt;1&lt;/a&gt;&amp;nbsp;„Éª&lt;/p&gt;
&lt;h3&gt;&lt;strong&gt;Why Build a Chinese Calligraphy&amp;nbsp;Classifier&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;Like any calligraphy, Chinese calligraphy is a form of art. Some great pieces written by some ancient masters have both great art value and economic values (selling at multi-million dollars on&amp;nbsp;auctions).&lt;/p&gt;
&lt;p&gt;&lt;img alt="*Jieshi Tie* by Song Dynasty politician and scholar Zeng Gong, $30,000,000" src="https://cdn-images-1.medium.com/max/2000/1*2lrTyRMYIcm6HfnojdgUvg.jpeg"&gt;&lt;em&gt;&lt;em&gt;Jieshi Tie&lt;/em&gt; by Song Dynasty politician and scholar Zeng Gong,&amp;nbsp;$30,000,000&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;There are multiple main styles/schools of calligraphy, mainly belongs to different dynasties. Each has its own way of shaping the character and arranging them. The differences are subtle and abstract. It makes sense to see if a trained deep learning model can do a good job of telling which style it is.
&lt;a href="https://www.datadriveninvestor.com/2019/03/03/editors-pick-5-machine-learning-books/"&gt;&lt;strong&gt;&lt;span class="caps"&gt;DDI&lt;/span&gt; Editor&amp;#8217;s Pick: 5 Machine Learning Books That Turn You from Novice to Expert | Data Driven‚Ä¶&lt;/strong&gt;
&lt;em&gt;The booming growth in the Machine Learning industry has brought renewed interest in people about Artificial‚Ä¶&lt;/em&gt;www.datadriveninvestor.com&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;I picked three&amp;nbsp;styles:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Lishu(Èö∂‰π¶)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Kaishu(Ê•∑‰π¶)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Xiaozhuan(Â∞èÁØÜ)&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;as a proof-of-concept. Once successful trained, the model could serve as a transfer learning base-model for the more fine-grained classifier( e.g. calligraphers classifier). This has some real-life value. From time to time, some ancient artifacts are discovered and some of them are calligraphy artworks. Sometimes it‚Äôs hard to tell whose work it is. Is it valuable (like undiscovered artwork by a famous&amp;nbsp;calligrapher)?&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;This calligrapher classifier can serve as a way to quickly identify artworks by great calligraphers. ( Finding diamond in the rough &lt;em&gt;üòâ&lt;/em&gt;)&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3&gt;Collecting&amp;nbsp;Data&lt;/h3&gt;
&lt;p&gt;To build a calligraphy classifier, we will need some calligraphy examples of each style. I did some search online and cannot find any good already-made data-set for different calligraphy styles. So I‚Äôll have to build it&amp;nbsp;myself.&lt;/p&gt;
&lt;p&gt;Building a images data-set isn‚Äôt hard thanks to Google‚Äôs Images search functionality and some JavaScript snippets. Here‚Äôs&amp;nbsp;how:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Go to &lt;a href="https://www.google.com/imghp?hl=en"&gt;Google Images&lt;/a&gt; and search for ‚ÄúÈö∂‰π¶ Â≠óÂ∏ñ ÁΩëÊ†º‚Äù (lishu, characters book, grid), this will give you the most relevant&amp;nbsp;results.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Scroll down to show more results, you‚Äôll hit the bottom with ‚Äò&lt;em&gt;Show more results&lt;/em&gt;‚Äô button. Click if you want more, but keep in mind that &lt;strong&gt;700&lt;/strong&gt; images is the maximum&amp;nbsp;here.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;img alt="Google search results for Lishu style" src="https://cdn-images-1.medium.com/max/2000/1*uQPNDb-qXO3mYQIHuxitMQ.png"&gt;&lt;em&gt;Google search results for Lishu&amp;nbsp;style&lt;/em&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Now is where the magic happens. Press Ctrl+Shift+J in Windows/Linux and Cmd+Opt+J in Mac to bring up the JavaScript ‚ÄòConsole‚Äô window of the browser. The following JavaScript snippet will get the URLs of each of the&amp;nbsp;images.&lt;/li&gt;
&lt;/ol&gt;
&lt;iframe src="https://medium.com/media/39e47823b2c7e8cdbb4ac527be5a4378" frameborder=0&gt;&lt;/iframe&gt;

&lt;ol&gt;
&lt;li&gt;If successfully run, a text file will be downloaded with all the URLs for the images in your search results. You can then set up a folder and use fast.ai‚Äôs ‚Äòdownload_images‚Äô function to download these&amp;nbsp;images.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;img alt="" src="https://cdn-images-1.medium.com/max/2000/1*19mOhygnBZfGmX4S2fD4ww.png"&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Rinse and repeat for other styles. You might want to put them into different folders like kaishu, xiaozhuan and put them all under a folder called train so later on, fast.ai can easily import them into the&amp;nbsp;model.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Alternatively, you can also go to Baidu.com for images search, using this &lt;a href="https://gist.github.com/wayofnumbers/39842bb909c04070de49e53c418d512f"&gt;snippet&lt;/a&gt; to automatically download the images you searched for. (Code too long to be put into this post, so I link it&amp;nbsp;here).&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h3&gt;Let‚Äôs Have a Look at the&amp;nbsp;Data&lt;/h3&gt;
&lt;p&gt;If you organize the downloaded images into train/lishu, train/kaishu, train/xiaozhuan, then you can run the following code to import them into and transformed accordingly, ready to fit a model.fast.ai‚Äôs powerfulImageDataBunch object, where all data is organized, splitted and transformed accordingly, ready to fit a&amp;nbsp;model.&lt;/p&gt;
&lt;p&gt;&lt;img alt="" src="https://cdn-images-1.medium.com/max/2000/1*hsF08GhTX9tjyov8hHzbFw.png"&gt;&lt;/p&gt;
&lt;p&gt;Note that we split the train/validation set with an 80/20 ratio, image resized to 224 which is a good default for any image recognition&amp;nbsp;task.&lt;/p&gt;
&lt;p&gt;Now that data is imported properly, let‚Äôs look at our&amp;nbsp;images:&lt;/p&gt;
&lt;p&gt;&lt;img alt="" src="https://cdn-images-1.medium.com/max/2000/1*F378nVvqW7o6lz6QxAB2gA.png"&gt;&lt;/p&gt;
&lt;p&gt;As we can see from the few examples above, the data-set is rather ‚Äòdirty‚Äô. The images are not properly cropped, with some side notes with different calligraphy style and some images only have one or two characters. But it‚Äôs &lt;span class="caps"&gt;OK&lt;/span&gt;. Let‚Äôs quickly train the model and see how it performs so we can gain some insights into our&amp;nbsp;data.&lt;/p&gt;
&lt;h3&gt;Quick and Dirty&amp;nbsp;Training&lt;/h3&gt;
&lt;p&gt;Let‚Äôs first create a model. We‚Äôll be using transfer learning and use ResNet50 as our model. Pre-trained weights will be&amp;nbsp;downloaded.&lt;/p&gt;
&lt;p&gt;&lt;img alt="" src="https://cdn-images-1.medium.com/max/2134/1*Zzy9-o-Q3K3BID_vZyRCoA.png"&gt;&lt;/p&gt;
&lt;p&gt;With 3 epoches of fit_one_cycle, we managed to reach a 90% accuracy rate on our validation set. Not&amp;nbsp;bad!&lt;/p&gt;
&lt;p&gt;&lt;img alt="" src="https://cdn-images-1.medium.com/max/2000/1*44IMsadGzm0-mF2SdrvUKA.png"&gt;&lt;/p&gt;
&lt;h3&gt;Unfreeze and Fine-Tune Our&amp;nbsp;Training&lt;/h3&gt;
&lt;p&gt;Since the fit_one_cycle function will freeze the initial layers and only training the last couple of layers to speed up the training speed(this approach works because usually for transfer learning, initial layers will capture basic features of the images that are not likely to change a lot), we can hopefully further improve our accuracy by unfreezing all the layers and train&amp;nbsp;again.&lt;/p&gt;
&lt;p&gt;&lt;img alt="" src="https://cdn-images-1.medium.com/max/2000/1*IxzL6yxuHV2nqmoXure_fg.png"&gt;&lt;/p&gt;
&lt;p&gt;We used the above lr_find function to find a good learning rate range. The key is to find the steepest slope (as indicated in the orange circle above) in the learning curve and slice it for further training. For example, in the above figure, the bottom of the curve is at 1e-03, then we can pick one point at 1/10 of that, which is 1e-04, and the other one at 1e-06 or 1e-05 (This is inspired from an experimental concept of ‚ÄòSuper-convergence‚Äô, described in details in &lt;a href="https://course.fast.ai"&gt;fast.ai course&lt;/a&gt;. Sometime you need to do a bit of experiment to find the best learning rate combination but then again, fast.ai is always preaching iterative and interactive approach.) The idea is still to train the first couple of layers slower and last couple layers&amp;nbsp;faster.&lt;/p&gt;
&lt;p&gt;Let‚Äôs train another two&amp;nbsp;epoch:&lt;/p&gt;
&lt;p&gt;&lt;img alt="" src="https://cdn-images-1.medium.com/max/2000/1*noUlINi_AE8NZyZfJ7koBQ.png"&gt;&lt;/p&gt;
&lt;p&gt;Slightly better and the validation_loss starts to surpass train_loss, a sign of overfitting. Let‚Äôs stop here and wrap things&amp;nbsp;up.&lt;/p&gt;
&lt;h3&gt;Results&amp;nbsp;Interpretation&lt;/h3&gt;
&lt;p&gt;We reached 90% accuracy. Not state-of-the-art but already pretty impressive considering we only have a roughly 700 images per class data-set. More data will definitely lead to better results. Let‚Äôs look at our results and see if we can find some&amp;nbsp;insights.&lt;/p&gt;
&lt;p&gt;&lt;img alt="" src="https://cdn-images-1.medium.com/max/2000/1*tyskbmlwBIE0roKxHHbseA.png"&gt;&lt;/p&gt;
&lt;p&gt;Using the ClassificationIntepretation object from fast.ai, we can easily calculate the top_losses and see what they&amp;nbsp;are:&lt;/p&gt;
&lt;p&gt;&lt;img alt="" src="https://cdn-images-1.medium.com/max/2000/1*3bL7M8zSjT-PLGVTqp3hEg.png"&gt;&lt;/p&gt;
&lt;p&gt;Look at the confusion matrix, the model does really well in recognize ‚Äòxiaozhuan‚Äô, probably due to its unique stroke&amp;nbsp;arrangements.&lt;/p&gt;
&lt;p&gt;&lt;img alt="" src="https://cdn-images-1.medium.com/max/2000/1*qtb-Te_AElPaO3mym-9RVw.png"&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;A couple of&amp;nbsp;insights:&lt;/strong&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;We still have totally wrong images like the grid one (2nd one on 1st row)
If there are too few (1st row, 1st column) or too many (2nd row, 2nd column) characters, the model will struggle.
Some image shows ‚Äòin-between‚Äô kind of styles which the model also had a hard time classify. Which is totally normal, since even human will have a hard time telling which style it belongs&amp;nbsp;to.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3&gt;Final&amp;nbsp;Thoughts&lt;/h3&gt;
&lt;p&gt;This experimental project actually works exceedingly well with fast.ai library. &lt;a href="undefined"&gt;Jeremy Howard&lt;/a&gt; said on the course and I quote here (not exactly word by word, but I hope I captured the gist of it.&amp;nbsp;üôè):&lt;/p&gt;
&lt;blockquote&gt;
&lt;h1&gt;fast.ai is a very opinionated library. Wherever we know a best default, we‚Äôll choose it for you. Whatever best practice we know works well, we‚Äôll do it for&amp;nbsp;you.&lt;/h1&gt;
&lt;/blockquote&gt;
&lt;p&gt;This is at least proven in this project. With only very few lines of code and very minimum efforts for data collection, we managed a 90% accurate model. I believe with more and better quality data. The state-of-the-art results could be achieved and our calligrapher classifier vision is not beyond&amp;nbsp;reach.&lt;/p&gt;
&lt;p&gt;&lt;img alt="fast.ai‚Äôs tagline: Making neural nets uncool again." src="https://cdn-images-1.medium.com/max/2400/0*Yo5w5gd2_CRC1MFl.jpg"&gt;&lt;em&gt;fast.ai‚Äôs tagline: Making neural nets uncool&amp;nbsp;again.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Finally, allow me to paraphrase above tagline with a Chinese&amp;nbsp;poet:&lt;/p&gt;
&lt;p&gt;&lt;img alt="‚ÄúWhere once the swallows knew the mansions of the great, They now to humbler homes would fly to nest and mate.‚Äú" src="https://cdn-images-1.medium.com/max/2000/1*g6k1Z7hyyeW_Y8Ge3GWmWQ.png"&gt;&lt;em&gt;‚ÄúWhere once the swallows knew the mansions of the great, They now to humbler homes would fly to nest and&amp;nbsp;mate.‚Äú&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Model &lt;a href="https://medium.com/@lymenlee/deep-learning-models-by-fast-ai-library-c1cccc13e2b3"&gt;1&lt;/a&gt;&lt;/p&gt;
&lt;iframe src="https://medium.com/media/0707f5c806284d01a4a13c7b13a91ce3" frameborder=0&gt;&lt;/iframe&gt;</content><category term="Machinelearning"></category><category term="AI"></category><category term="fastai"></category><category term="deeplearning"></category><category term="calligraphy"></category></entry><entry><title>Thoughts on Andrew Ng‚Äôs Machine Learning¬†Course</title><link href="https://wayofnumbers.github.io/thoughts-on-andrew-ng-machine-learning-course.html" rel="alternate"></link><published>2019-09-09T00:00:00-05:00</published><updated>2019-09-09T00:00:00-05:00</updated><author><name>Michael Li</name></author><id>tag:wayofnumbers.github.io,2019-09-09:/thoughts-on-andrew-ng-machine-learning-course.html</id><summary type="html">&lt;p&gt;Review about Andrew Ng&amp;#8217;s Machine Learning&amp;nbsp;course&lt;/p&gt;</summary><content type="html">&lt;h1&gt;Thoughts on Andrew Ng‚Äôs Machine Learning&amp;nbsp;Course&lt;/h1&gt;
&lt;p&gt;The good, the bad, and the&amp;nbsp;beautiful&lt;/p&gt;
&lt;p&gt;&lt;img alt="" src="https://cdn-images-1.medium.com/max/2400/1*-7P4wesf7eSx46XxHV9_wg.png"&gt;&lt;/p&gt;
&lt;p&gt;Just finished &lt;a href="undefined"&gt;Andrew Ng&lt;/a&gt;‚Äôs Machine Learning course on &lt;a href="https://www.coursera.org"&gt;Coursera&lt;/a&gt;, and it‚Äôs &lt;span class="caps"&gt;GREAT&lt;/span&gt;! Here some thoughts and&amp;nbsp;observations:&lt;/p&gt;
&lt;h2&gt;What‚Äôs great about&amp;nbsp;it&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;&lt;em&gt;Well designed learning&amp;nbsp;curve&lt;/em&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;img alt="EVE Online game‚Äôs (in)famous crazy learning curve" src="https://cdn-images-1.medium.com/max/2000/1*LAjfLlfo98ej8mUIWYhnzA.jpeg"&gt;
&lt;em&gt;&lt;span class="caps"&gt;EVE&lt;/span&gt; Online game‚Äôs (in)famous crazy learning&amp;nbsp;curve&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;This is especially important for people that never heard of Machine Learning. Not assuming the student have any prior knowledge and gradually guide them through complex concept makes the learning experience challenging yet still&amp;nbsp;fun.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;em&gt;Avoid complex math, yet find a way to still enable student to do &lt;span class="caps"&gt;ML&lt;/span&gt;&amp;nbsp;(meme)&lt;/em&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;img alt="The Andrew Ng ‚ÄòSilent Protector‚Äô Meme" src="https://cdn-images-1.medium.com/max/2000/1*YylTTtIEkCcx-EFh5g2Vsw.jpeg"&gt;
&lt;em&gt;The Andrew Ng ‚ÄòSilent Protector‚Äô&amp;nbsp;Meme&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Maybe the biggest fear for people want to get into Machine Learning and &lt;span class="caps"&gt;AI&lt;/span&gt; is ‚ÄòI‚Äôm not a math person‚Äô. Being able to not getting into too much math yet still explain clearly the concept is invaluable, especially for totally green&amp;nbsp;guys.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href="https://www.gnu.org/software/octave/"&gt;*Octave&lt;/a&gt;/&lt;a href="https://www.mathworks.com/products/matlab.html"&gt;Matlab&lt;/a&gt; is more ‚Äòmath‚Äô like, less digression on programming language&amp;nbsp;itself*&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Some people might not agree with me on this. Yes Octave/Matlab doesn‚Äôt have all the fancy libraries like &lt;a href="https://scikit-learn.org/"&gt;scikit-learn&lt;/a&gt; and Pandas, yet it‚Äôs very expressive when it comes to represent math equations. Transfer equations from class to Matlab code is easier than Python &lt;span class="caps"&gt;IMHO&lt;/span&gt;.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;em&gt;Cover most popular models, good&amp;nbsp;foundation&lt;/em&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Linear/Logistic&amp;nbsp;Regression&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;span class="caps"&gt;SVM&lt;/span&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Neural&amp;nbsp;Network&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Collaborative&amp;nbsp;Filtering&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Anomaly&amp;nbsp;Detection&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;K-Means&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;span class="caps"&gt;PCA&lt;/span&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;With all these algorithms/models under your belt, you are ready to solve a lot of problems with Machine&amp;nbsp;Learning.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;em&gt;Provide practical &lt;span class="caps"&gt;ML&lt;/span&gt; projects knowledge, not only algorithm and programming&lt;/em&gt;
Besides theory, the course also offers very practical Machine Learning project knowledge, hot to build a pipeline, how to structure the problem solving,&amp;nbsp;etc.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;em&gt;Well designed quizzes and assignments, as part of learning&amp;nbsp;too&lt;/em&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;I was always amazed by how well the quizzes and assignments are designed. They are challenging, yet with some efforts achievable, and at the same time offer some new perspective on the lesson. I always learned a few new things doing those and totally enjoyed&amp;nbsp;them.&lt;/p&gt;
&lt;h2&gt;What‚Äôs&amp;nbsp;lacking?&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;&lt;em&gt;A bit dated on libraries and&amp;nbsp;architectures&lt;/em&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;em&gt;You won‚Äôt find the high-level &lt;a href="http://keras.io/"&gt;Keras&lt;/a&gt;, &lt;a href="https://www.tensorflow.org/"&gt;TensorFlow&lt;/a&gt; or &lt;a href="https://pytorch.org/"&gt;PyTorth&lt;/a&gt; here, but this course is about foundation of Machine Learning and it delivered on its promise.
&lt;/em&gt;2. Could use more examples/applications of &lt;span class="caps"&gt;ML&lt;/span&gt; for&amp;nbsp;motivation&lt;/p&gt;
&lt;p&gt;There are a lot of exciting development and applications on &lt;span class="caps"&gt;ML&lt;/span&gt;/&lt;span class="caps"&gt;AI&lt;/span&gt; field. If students could be exposed to more of those, it will give them more reasons to keep&amp;nbsp;learning.&lt;/p&gt;
&lt;h2&gt;Final&amp;nbsp;Thoughts&lt;/h2&gt;
&lt;p&gt;&lt;img alt="‚ÄòDon‚Äôt worry about it if you don‚Äôt understand‚Äô ‚Ñ¢Ô∏è" src="https://cdn-images-1.medium.com/max/2560/1*yIPIuNIn6ar7MvQnNqlWlQ.jpeg"&gt;&lt;em&gt;‚ÄòDon‚Äôt worry about it if you don‚Äôt understand‚Äô&amp;nbsp;‚Ñ¢Ô∏è&lt;/em&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Overall great course if you are totally new to Machine Learning. All of the well thought out contents coupled with &lt;a href="undefined"&gt;Andrew Ng&lt;/a&gt;‚Äôs gentle and calm explanation makes the learning experience a breeze and a pleasant journey. The road ahead for Machine Learning might not be so smooth after all but having a ‚Äòsoothing‚Äô start could carry you a long way.&amp;nbsp;üëç&lt;/p&gt;
&lt;/blockquote&gt;</content><category term="machinelearning"></category></entry><entry><title>Types of Optimization Algorithms used in Neural Networks and Ways to Optimize Gradient¬†Descent</title><link href="https://wayofnumbers.github.io/Typtes-of-optimization-algorithms.html" rel="alternate"></link><published>2018-02-26T17:00:00-06:00</published><updated>2018-02-26T17:00:00-06:00</updated><author><name>Internet</name></author><id>tag:wayofnumbers.github.io,2018-02-26:/Typtes-of-optimization-algorithms.html</id><summary type="html">&lt;p&gt;Types of Optimization Algorithms used in Neural Networks and Ways to Optimize Gradient&amp;nbsp;Descent&lt;/p&gt;</summary><content type="html">&lt;p&gt;&lt;a href="https://towardsdatascience.com/types-of-optimization-algorithms-used-in-neural-networks-and-ways-to-optimize-gradient-95ae5d39529f"&gt;&lt;strong&gt;Original&amp;nbsp;Story&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="https://towardsdatascience.com/@anishsingh20"&gt;Anish Singh Walia&lt;/a&gt;:        &lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;If your input data is sparse then methods such as &lt;strong&gt;&lt;span class="caps"&gt;SGD&lt;/span&gt;,&lt;span class="caps"&gt;NAG&lt;/span&gt; and momentum&lt;/strong&gt; are inferior and perform poorly. &lt;strong&gt;For sparse data sets one should use one of the adaptive learning-rate methods.&lt;/strong&gt; An additional benefit is that we won‚Äôt need to adjust the learning rate but likely achieve the best results with the default value.
If one wants fast convergence and train a deep Neural Network Model or a highly complex Neural Network then &lt;strong&gt;Adam or any other Adaptive learning rate techniques&lt;/strong&gt; should be used because they outperforms every other optimization&amp;nbsp;algorithms.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;One thing about Machine Learning the overal depth of the topics and algorithms makes it so easy to totally &lt;em&gt;&amp;#8216;sink&amp;#8217;&lt;/em&gt; yourself into it. And there is always something to dig. This article provides a view from a higher ground and compare different optimization algorithms and their application areas, thus pulling you out of the deep hole of deep&amp;nbsp;learning. &lt;/p&gt;
&lt;p&gt;A more visual example of these algorithms, see these two beautifully crafted&amp;nbsp;animations:&lt;/p&gt;
&lt;p&gt;&lt;img alt="SGD optimization on loss surface contours" src="https://wayofnumbers.github.io/images/optimization-algorithem-1.gif" title="SGD optimization on loss surface contours"&gt;
&lt;div style="text-align: center;"&gt;&lt;span class="caps"&gt;SGD&lt;/span&gt; optimization on loss surface contours&lt;/div&gt;
&lt;br&gt;&lt;/p&gt;
&lt;p&gt;&lt;img alt="SGD optimization on saddle point" src="https://wayofnumbers.github.io/images/optimization-algorithem-2.gif" title="SGD optimization on saddle point"&gt;
&lt;div style="text-align: center;"&gt;&lt;span class="caps"&gt;SGD&lt;/span&gt; optimization on saddle point&lt;/div&gt;&lt;/p&gt;</content><category term="machinelearning"></category><category term="AI"></category><category term="Optimization Algorithm"></category><category term="Gradient Descent"></category><category term="Neural Networks"></category></entry><entry><title>The AI¬†Shortage</title><link href="https://wayofnumbers.github.io/The-AI-Shortage.html" rel="alternate"></link><published>2018-02-23T17:00:00-06:00</published><updated>2018-02-23T17:00:00-06:00</updated><author><name>Internet</name></author><id>tag:wayofnumbers.github.io,2018-02-23:/The-AI-Shortage.html</id><summary type="html">&lt;p&gt;&lt;span class="caps"&gt;AI&lt;/span&gt; talent shortage is not getting better any time&amp;nbsp;soon&amp;#8230;&lt;/p&gt;</summary><content type="html">&lt;p&gt;&lt;a href="https://medium.com/@Moscow25/the-ai-talent-shortage-704d8cf0c4cc"&gt;&lt;strong&gt;Original&amp;nbsp;Story&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="https://medium.com/@Moscow25"&gt;Nikolai Yakovenko&lt;/a&gt; from &lt;span class="caps"&gt;NVIDIA&lt;/span&gt;:        &lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;But when I look for a designer, a Java developer, a real estate agent, etc‚Ää‚Äî‚Ääsome are way better than others and deserve to get paid more than an &lt;span class="caps"&gt;AI&lt;/span&gt; researcher‚Ää‚Äî‚Ääbut you‚Äôre fundamentally talking about pulling from a large well-balanced pool. It‚Äôs mostly an information game, and a matter of getting a little better than you need, but not much more than you can afford or should be paying.
In &lt;span class="caps"&gt;AI&lt;/span&gt;, it‚Äôs different. There just aren‚Äôt enough people to go around. And there aren‚Äôt enough people for every good project that can be attempted. Either academic, or something that if it works, can save the company&amp;nbsp;$1M.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;The booming of a new disruptive technology always did this to the industry as well as the talent pool. It drives money into investing on the next big thing, and the money lures more talents into the field. There will be a shortage in the very beginning, and there will always be a surplus at the end of the curve. I&amp;#8217;m afraid &lt;span class="caps"&gt;AI&lt;/span&gt; won&amp;#8217;t be any different. It&amp;#8217;s just that the curve will take 10 maybe more years to unfold so it&amp;#8217;s not too late to get in the game if you think you have the stuff, since at the end of day, people with talent and grit will win, in every new technology &amp;#8216;gold&amp;nbsp;rush&amp;#8217;. &lt;/p&gt;</content><category term="machinelearning"></category><category term="AI"></category></entry></feed>